{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **ENGLISH TO INDIC**"
      ],
      "metadata": {
        "id": "pwObchVudE7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.14.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9P8D8d3t5PM",
        "outputId": "b27fd5d8-1979-46e7-9081-51ca0da7ec73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.14.0 in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (68.2.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (2.14.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.14.0) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEdsMuWrt9gX",
        "outputId": "73cee5bb-b3eb-4793-afd8-7e7c2aa169cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!git clone https://github.com/AI4Bharat/IndicTrans2.git"
      ],
      "metadata": {
        "id": "QHZ61zExuHTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import re\n",
        "import os\n",
        "import time\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "o5diXgv1urGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%cd /content/IndicTrans2/huggingface_interface"
      ],
      "metadata": {
        "id": "U3vs7FkIGSxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!python3 -m pip install nltk sacremoses pandas regex mock transformers>=4.33.2 mosestokenizer\n",
        "!python3 -c \"import nltk; nltk.download('punkt')\"\n",
        "!python3 -m pip install bitsandbytes scipy accelerate datasets\n",
        "!python3 -m pip install sentencepiece\n",
        "\n",
        "!git clone https://github.com/VarunGumma/IndicTransTokenizer\n",
        "%cd IndicTransTokenizer\n",
        "!python3 -m pip install --editable ./\n",
        "%cd .."
      ],
      "metadata": {
        "id": "ddkRAXQ2Git0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ENCODER_LEN = 100\n",
        "DECODER_LEN = 100\n",
        "BATCH_SIZE = 32\n",
        "BUFFER_SIZE = BATCH_SIZE*4"
      ],
      "metadata": {
        "id": "LRUq5zUbJ8iW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load each dataset\n",
        "train_df_nepali = pd.read_csv(\"/content/drive/MyDrive/dataset/nepali.csv\")\n",
        "train_df_assamese = pd.read_csv(\"/content/drive/MyDrive/dataset/assamese.csv\")\n",
        "train_df_bodo = pd.read_csv(\"/content/drive/MyDrive/dataset/bodo.csv\")\n",
        "train_df_khasi = pd.read_csv(\"/content/drive/MyDrive/dataset/khasi.csv\")\n",
        "train_df_manipuri = pd.read_csv(\"/content/drive/MyDrive/dataset/manipuri.csv\")\n",
        "train_df_mizo = pd.read_csv(\"/content/drive/MyDrive/dataset/mizo.csv\")\n",
        "\n"
      ],
      "metadata": {
        "id": "kTFnn_OCJ-Ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_assamese.drop_duplicates()\n",
        "train_df_bodo.drop_duplicates()\n",
        "train_df_nepali.drop_duplicates()\n",
        "train_df_mizo.drop_duplicates()\n",
        "train_df_khasi.drop_duplicates()\n",
        "train_df_manipuri.drop_duplicates()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "pqS2g62OKAKH",
        "outputId": "6cbc8e5f-203b-4d77-9d5e-11f82e3544d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 ENGLISH  \\\n",
              "0            Alison Masturbate Give Me Emotions 12: 00\\n   \n",
              "1      Social Security, Social Security, and Social S...   \n",
              "2      Late Nrityashilpi Amalashankar, Chief Minister...   \n",
              "3              Teri Ha Papdi has a fire cracker in it.\\n   \n",
              "4                      But that doesn't mean we can't.\\n   \n",
              "...                                                  ...   \n",
              "60225  Taxes and levies not refundable and duties, ce...   \n",
              "60226                           b. at least two people\\n   \n",
              "60227  These rankings are made after evaluating the b...   \n",
              "60228      Mera teri gali mein - Jeena teri gali mein.\\n   \n",
              "60229          On: July 30, 2018 In: भारतीय भारतीय में\\n   \n",
              "\n",
              "                                                MANIPURI  \n",
              "0         একাকী হটি এলিসন হস্তমৈথুন Give Me আবেগ 12:00\\n  \n",
              "1      ওল পোৎ পিবা থবক থিবা বিলস শকখঙচেশিং সোশ্যাল সি...  \n",
              "2      প্রয়াত নৃত্যশিল্পী অমলাশঙ্কর, মুখ্যমন্ত্রীর শ...  \n",
              "3                         তেরি হা পাপদি দা মৈ ক্রেতা আ\\n  \n",
              "4       অদুবু মসিনা ঐখোয় য়ারে পেল্লে হায়বা য়াদ্রি।\\n  \n",
              "...                                                  ...  \n",
              "60225  তেক্সশিং অমসুং লেবিসশিং রিফন্দ তৌদ্রিবা অমসুং ...  \n",
              "60226          3. n য়ামদ্রবদা মী অনী খূৎ থাদুনা খৎনবা\\n  \n",
              "60227  অওনবশিংনা পুরকপা কান্নবশিং য়েংলবা মতুংদা হায়...  \n",
              "60228           মরনা তেরী গলী মেঁ - জীনা তেরী গলী মেঁ।\\n  \n",
              "60229                on: জুলাই ০২, ২০২০ In: জন্মমৃত্যু\\n  \n",
              "\n",
              "[60230 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8615c50d-bfae-42d9-bd56-207d5ae4f20d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ENGLISH</th>\n",
              "      <th>MANIPURI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Alison Masturbate Give Me Emotions 12: 00\\n</td>\n",
              "      <td>একাকী হটি এলিসন হস্তমৈথুন Give Me আবেগ 12:00\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Social Security, Social Security, and Social S...</td>\n",
              "      <td>ওল পোৎ পিবা থবক থিবা বিলস শকখঙচেশিং সোশ্যাল সি...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Late Nrityashilpi Amalashankar, Chief Minister...</td>\n",
              "      <td>প্রয়াত নৃত্যশিল্পী অমলাশঙ্কর, মুখ্যমন্ত্রীর শ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Teri Ha Papdi has a fire cracker in it.\\n</td>\n",
              "      <td>তেরি হা পাপদি দা মৈ ক্রেতা আ\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>But that doesn't mean we can't.\\n</td>\n",
              "      <td>অদুবু মসিনা ঐখোয় য়ারে পেল্লে হায়বা য়াদ্রি।\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60225</th>\n",
              "      <td>Taxes and levies not refundable and duties, ce...</td>\n",
              "      <td>তেক্সশিং অমসুং লেবিসশিং রিফন্দ তৌদ্রিবা অমসুং ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60226</th>\n",
              "      <td>b. at least two people\\n</td>\n",
              "      <td>3. n য়ামদ্রবদা মী অনী খূৎ থাদুনা খৎনবা\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60227</th>\n",
              "      <td>These rankings are made after evaluating the b...</td>\n",
              "      <td>অওনবশিংনা পুরকপা কান্নবশিং য়েংলবা মতুংদা হায়...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60228</th>\n",
              "      <td>Mera teri gali mein - Jeena teri gali mein.\\n</td>\n",
              "      <td>মরনা তেরী গলী মেঁ - জীনা তেরী গলী মেঁ।\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60229</th>\n",
              "      <td>On: July 30, 2018 In: भारतीय भारतीय में\\n</td>\n",
              "      <td>on: জুলাই ০২, ২০২০ In: জন্মমৃত্যু\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60230 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8615c50d-bfae-42d9-bd56-207d5ae4f20d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8615c50d-bfae-42d9-bd56-207d5ae4f20d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8615c50d-bfae-42d9-bd56-207d5ae4f20d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-16fef386-170e-4c50-a6c0-8bc1ef3c677b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-16fef386-170e-4c50-a6c0-8bc1ef3c677b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-16fef386-170e-4c50-a6c0-8bc1ef3c677b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"train_df_manipuri\",\n  \"rows\": 60230,\n  \"fields\": [\n    {\n      \"column\": \"ENGLISH\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 59432,\n        \"samples\": [\n          \"The topic provides information related to the Juvenile Justice (Care and Protection of Children) Act, 2015.\\n\",\n          \"Strengthen institutional mechanisms to fund and support implementation.\\n\",\n          \"The collection of Barak Valley has been preserved - probably only in the sixties - by B.\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MANIPURI\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 60229,\n        \"samples\": [\n          \"\\u09b8\\u09c7\\u0995\\u09cd\\u09af\\u09c1\\u09b0\\u09bf\\u099f\\u09bf\\u0997\\u09c0 \\u09af\\u09bc\\u09be\\u09a8\\u09be \\u09ae\\u09c0 \\u09ea\\u09eb \\u09aa\\u09cb\\u099c\\u09bf\\u099f\\u09bf\\u09ac \\u0987\\u0996\\u09bf\\n\",\n          \"\\u09ae\\u09cc\\u0996\\u09bf\\u0995, \\u09aa\\u09cd\\u09b0\\u09a4\\u09bf\\u09ae\\u09be, femdom, \\u0996\\u09c7\\u09b2\\u09a8\\u09be\\n\",\n          \"\\u0987\\u09a8\\u09ab\\u09cb\\u09b0\\u09cd\\u09ae\\u09c7\\u09b2 \\u09ae\\u09c0\\u09ab\\u09ae \\u0985\\u09b8\\u09bf\\u09a6\\u09be \\u0985\\u09a6\\u09cb\\u09ae\\u09cd\\u09ac\\u09c1 \\u09a4\\u09b0\\u09be\\u09ae\\u09cd\\u09a8\\u09be \\u0993\\u0995\\u099a\\u09ac\\u09a6\\u09be \\u0990\\u09b9\\u09be\\u0995 \\u09a8\\u09c1\\u0982\\u0999\\u09be\\u0987\\u09ac\\u09be \\u09ab\\u09be\\u0993\\u0987\\u0964\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Remove unwanted characters, convert text to lowercase, and remove nan values for the 'ENGLISH' column\n",
        "train_df_nepali['ENGLISH'] = train_df_nepali['ENGLISH'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', str(x).lower()) if pd.notnull(x) else '')\n",
        "\n",
        "# Remove unwanted characters, convert text to lowercase, and remove nan values for the 'बड़ो' column\n",
        "train_df_nepali['NEPALI'] = train_df_nepali['NEPALI'].apply(lambda x: re.sub(r'[^a-zA-Z\\u0900-\\u097F\\s]', '', str(x).lower()) if pd.notnull(x) else '')\n",
        "\n",
        "# Remove punctuation for the 'ENGLISH' column\n",
        "train_df_nepali['ENGLISH'] = train_df_nepali['ENGLISH'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
        "\n",
        "# Remove punctuation for the 'बड़ो' column\n",
        "train_df_nepali['NEPALI'] = train_df_nepali['NEPALI'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
        "\n",
        "# Remove extra whitespace for the 'ENGLISH' column\n",
        "train_df_nepali['ENGLISH'] = train_df_nepali['ENGLISH'].apply(lambda x: re.sub(r'\\s+', ' ', x.strip()))\n",
        "\n",
        "# Remove extra whitespace for the 'बड़ो' column\n",
        "train_df_nepali['NEPALI'] = train_df_nepali['NEPALI'].apply(lambda x: re.sub(r'\\s+', ' ', x.strip()))\n",
        "\n",
        "# Remove rows with empty values\n",
        "train_df_nepali.replace('', np.nan, inplace=True)\n",
        "train_df_nepali.dropna(subset=['ENGLISH', 'NEPALI'], inplace=True)\n",
        "\n",
        "# Save the cleaned Nepali data to a new CSV file\n",
        "train_df_nepali.to_csv('nepali.csv', columns=['ENGLISH', 'NEPALI'], index=False)"
      ],
      "metadata": {
        "id": "g65irtxMKO_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_manipuri_text(text):\n",
        "    # Replace characters not in the Manipuri script with a space\n",
        "    cleaned_text = re.sub(r'[^\\u0980-\\u09FF\\s]', ' ', str(text).lower()) if pd.notnull(text) else ''\n",
        "    # Remove extra whitespace\n",
        "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text.strip())\n",
        "    return cleaned_text\n",
        "# Remove unwanted characters, convert text to lowercase, and remove nan values for the 'ENGLISH' column\n",
        "train_df_manipuri['ENGLISH'] = train_df_manipuri['ENGLISH'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', str(x).lower()) if pd.notnull(x) else '')\n",
        "\n",
        "# Remove punctuation for the 'ENGLISH' column\n",
        "train_df_manipuri['ENGLISH'] = train_df_manipuri['ENGLISH'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
        "\n",
        "# Remove extra whitespace for the 'ENGLISH' column\n",
        "train_df_manipuri['ENGLISH'] = train_df_manipuri['ENGLISH'].apply(lambda x: re.sub(r'\\s+', ' ', x.strip()))\n",
        "\n",
        "# Apply the cleaning function to the 'MANIPURI' column\n",
        "train_df_manipuri['MANIPURI'] = train_df_manipuri['MANIPURI'].apply(clean_manipuri_text)\n",
        "\n",
        "# Remove punctuation for the 'MANIPURI' column\n",
        "train_df_manipuri['MANIPURI'] = train_df_manipuri['MANIPURI'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
        "\n",
        "# Remove rows with empty values\n",
        "train_df_manipuri.replace('', np.nan, inplace=True)\n",
        "train_df_manipuri.dropna(subset=['ENGLISH', 'MANIPURI'], inplace=True)\n",
        "\n",
        "# Save the cleaned Manipuri data to a new CSV file\n",
        "train_df_manipuri.to_csv('manipuri.csv', columns=['ENGLISH', 'MANIPURI'], index=False)\n",
        "\n",
        "# Display the cleaned DataFrame\n",
        "print(train_df_manipuri[['ENGLISH', 'MANIPURI']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhe1rNKIKRKB",
        "outputId": "597a771f-b993-4113-b25a-68df023e7e5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 ENGLISH  \\\n",
            "0                     alison masturbate give me emotions   \n",
            "1      social security social security and social sec...   \n",
            "2      late nrityashilpi amalashankar chief ministers...   \n",
            "3                 teri ha papdi has a fire cracker in it   \n",
            "4                           but that doesnt mean we cant   \n",
            "...                                                  ...   \n",
            "60225  taxes and levies not refundable and duties ces...   \n",
            "60226                              b at least two people   \n",
            "60227  these rankings are made after evaluating the b...   \n",
            "60228           mera teri gali mein jeena teri gali mein   \n",
            "60229                                         on july in   \n",
            "\n",
            "                                                MANIPURI  \n",
            "0                         একাকী হটি এলিসন হস্তমৈথুন আবেগ  \n",
            "1      ওল পোৎ পিবা থবক থিবা বিলস শকখঙচেশিং সোশ্যাল সি...  \n",
            "2      প্রয়াত নৃত্যশিল্পী অমলাশঙ্কর মুখ্যমন্ত্রীর শো...  \n",
            "3                           তেরি হা পাপদি দা মৈ ক্রেতা আ  \n",
            "4          অদুবু মসিনা ঐখোয় য়ারে পেল্লে হায়বা য়াদ্রি  \n",
            "...                                                  ...  \n",
            "60225  তেক্সশিং অমসুং লেবিসশিং রিফন্দ তৌদ্রিবা অমসুং ...  \n",
            "60226                 য়ামদ্রবদা মী অনী খূৎ থাদুনা খৎনবা  \n",
            "60227  অওনবশিংনা পুরকপা কান্নবশিং য়েংলবা মতুংদা হায়...  \n",
            "60228                মরনা তেরী গলী মেঁ জীনা তেরী গলী মেঁ  \n",
            "60229                           জুলাই ০২ ২০২০ জন্মমৃত্যু  \n",
            "\n",
            "[60135 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Remove unwanted characters, convert text to lowercase, and remove nan values for the 'ENGLISH' column\n",
        "train_df_assamese['ENGLISH'] = train_df_assamese['ENGLISH'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', str(x).lower()) if pd.notnull(x) else '')\n",
        "\n",
        "# Remove punctuation for the 'ENGLISH' column\n",
        "train_df_assamese['ENGLISH'] = train_df_assamese['ENGLISH'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
        "\n",
        "# Remove extra whitespace for the 'ENGLISH' column\n",
        "train_df_assamese['ENGLISH'] = train_df_assamese['ENGLISH'].apply(lambda x: re.sub(r'\\s+', ' ', x.strip()))\n",
        "\n",
        "# Remove unwanted characters, convert text to lowercase, and remove nan values for the 'ASSAMESE' column\n",
        "train_df_assamese['ASSAMESE'] = train_df_assamese['ASSAMESE'].apply(lambda x: re.sub(r'[^a-zA-Z\\u0980-\\u09FF\\s]', '', str(x).lower()) if pd.notnull(x) else '')\n",
        "\n",
        "# Remove punctuation for the 'ASSAMESE' column\n",
        "train_df_assamese['ASSAMESE'] = train_df_assamese['ASSAMESE'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
        "\n",
        "# Remove extra whitespace for the 'ASSAMESE' column\n",
        "train_df_assamese['ASSAMESE'] = train_df_assamese['ASSAMESE'].apply(lambda x: re.sub(r'\\s+', ' ', x.strip()))\n",
        "\n",
        "# Remove rows with empty values\n",
        "train_df_assamese.replace('', np.nan, inplace=True)\n",
        "train_df_assamese.dropna(subset=['ENGLISH', 'ASSAMESE'], inplace=True)\n",
        "\n",
        "# Save the cleaned Assamese data to a new CSV file\n",
        "train_df_assamese.to_csv('assamese.csv', columns=['ENGLISH', 'ASSAMESE'], index=False)\n",
        "\n",
        "# Display the cleaned DataFrame\n",
        "print(train_df_assamese[['ENGLISH','ASSAMESE']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUELzn-2Kz3W",
        "outputId": "b4ca8095-7b0c-4d72-d1b7-f56cc4409d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  ENGLISH  \\\n",
            "0                                        tie up long hair   \n",
            "1       nevertheless he gave this assurance he that ha...   \n",
            "2       david wrote many things you yourself have done...   \n",
            "3       to many people today a martyr is more or less ...   \n",
            "4       after protests were conducted over the decisio...   \n",
            "...                                                   ...   \n",
            "141228                                        what is god   \n",
            "141229     jehovahs feelings toward the haughty are clear   \n",
            "141230  as we approach the end of this system of thing...   \n",
            "141231  what can be said about the religious situation...   \n",
            "141232  i won my battle with postpartum depression awa...   \n",
            "\n",
            "                                                 ASSAMESE  \n",
            "0                                     মেলি থোৱা দীঘল চুলি  \n",
            "1       যিয়েই নহওঁক যিসকলে এই কাৰ্য্য প্ৰাণপণে কৰা চেষ...  \n",
            "2       ইয়োব ৩৮ ৪ ৬ পদত উল্লেখ কৰা লিখনীৰ পৰা আমি কি জ...  \n",
            "3       এই সন্দৰ্ভত তেওঁ পীলাতক এইদৰে কৈছিল যে সত্যতাৰ...  \n",
            "4       কৰনাৰ বিভীষিকাৰ মাজতো গুৱাহাটী বিশ্ববিদ্যালয়ে ...  \n",
            "...                                                   ...  \n",
            "141228                                    গতিকে ভগৱান কোন  \n",
            "141229                                         বৰ্ণনা কৰক  \n",
            "141230  যীচুৱে তেওঁৰ শিষ্যসকলক পৰিচালিত কৰিবলৈ কেনেকৈ ...  \n",
            "141231  দ্যা ৱৰ্ল্ড আলমেনাক নামৰ কিতাপখনে ধৰ্ম্ম অনুসৰ...  \n",
            "141232  প্ৰসবোত্তৰ বাবে হোৱা মানসিক অৱসাদৰ ওপৰত জয়ী হো...  \n",
            "\n",
            "[141233 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove unwanted characters, convert text to lowercase, and remove nan values for the 'ENGLISH' column\n",
        "train_df_khasi['ENGLISH'] = train_df_khasi['ENGLISH'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', str(x).lower()) if pd.notnull(x) else '')\n",
        "\n",
        "# Remove unwanted characters, convert text to lowercase, and remove nan values for the 'KHASI_DEVA' column\n",
        "train_df_khasi['KHASI'] = train_df_khasi['KHASI'].apply(lambda x: re.sub(r'[^a-zA-Z\\u0900-\\u097F\\s]', '', str(x).lower()) if pd.notnull(x) else '')\n",
        "\n",
        "# Remove punctuation for the 'ENGLISH' column\n",
        "train_df_khasi['ENGLISH'] = train_df_khasi['ENGLISH'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
        "\n",
        "# Remove punctuation for the 'KHASI' column\n",
        "train_df_khasi['KHASI'] = train_df_khasi['KHASI'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
        "\n",
        "# Remove extra whitespace for the 'ENGLISH' column\n",
        "train_df_khasi['ENGLISH'] = train_df_khasi['ENGLISH'].apply(lambda x: re.sub(r'\\s+', ' ', x.strip()))\n",
        "\n",
        "# Remove extra whitespace for the 'KHASI' column\n",
        "train_df_khasi['KHASI'] = train_df_khasi['KHASI'].apply(lambda x: re.sub(r'\\s+', ' ', x.strip()))\n",
        "\n",
        "# Remove rows with empty values\n",
        "train_df_khasi.replace('', np.nan, inplace=True)\n",
        "train_df_khasi.dropna(subset=['ENGLISH', 'KHASI'], inplace=True)\n",
        "\n",
        "# Save the cleaned Khasi data to a new CSV file\n",
        "train_df_khasi.to_csv('khasi.csv', columns=['ENGLISH', 'KHASI'], index=False)"
      ],
      "metadata": {
        "id": "6Qscq8kFK3Up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove unwanted characters, convert text to lowercase, and remove nan values for the 'ENGLISH' column\n",
        "train_df_mizo['ENGLISH'] = train_df_mizo['ENGLISH'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', str(x).lower()) if pd.notnull(x) else '')\n",
        "\n",
        "# Remove unwanted characters, convert text to lowercase, and remove nan values for the 'MIZO_DEVA' column\n",
        "train_df_mizo['MIZO'] = train_df_mizo['MIZO'].apply(lambda x: re.sub(r'[^a-zA-Z\\u0900-\\u097F\\s]', '', str(x).lower()) if pd.notnull(x) else '')\n",
        "\n",
        "# Remove punctuation for the 'ENGLISH' column\n",
        "train_df_mizo['ENGLISH'] = train_df_mizo['ENGLISH'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
        "\n",
        "# Remove punctuation for the 'MIZO' column\n",
        "train_df_mizo['MIZO'] = train_df_mizo['MIZO'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
        "\n",
        "# Remove extra whitespace for the 'ENGLISH' column\n",
        "train_df_mizo['ENGLISH'] = train_df_mizo['ENGLISH'].apply(lambda x: re.sub(r'\\s+', ' ', x.strip()))\n",
        "\n",
        "# Remove extra whitespace for the 'MIZO' column\n",
        "train_df_mizo['MIZO'] = train_df_mizo['MIZO'].apply(lambda x: re.sub(r'\\s+', ' ', x.strip()))\n",
        "\n",
        "# Remove rows with empty values\n",
        "train_df_mizo.replace('', np.nan, inplace=True)\n",
        "train_df_mizo.dropna(subset=['ENGLISH', 'MIZO'], inplace=True)\n",
        "\n",
        "# Save the cleaned Mizo data to a new CSV file\n",
        "train_df_mizo.to_csv('mizo.csv', columns=['ENGLISH', 'MIZO'], index=False)\n"
      ],
      "metadata": {
        "id": "-rMNRI2vK9xT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Remove unwanted characters, convert text to lowercase, and remove nan values for the 'ENGLISH' column\n",
        "train_df_bodo['ENGLISH'] = train_df_bodo['ENGLISH'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', str(x).lower()) if pd.notnull(x) else '')\n",
        "\n",
        "# Remove unwanted characters, convert text to lowercase, and remove nan values for the 'BODO_DEVA' column\n",
        "train_df_bodo['BODO'] = train_df_bodo['BODO'].apply(lambda x: re.sub(r'[^a-zA-Z\\u0900-\\u097F\\s]', '', str(x).lower()) if pd.notnull(x) else '')\n",
        "\n",
        "# Remove punctuation for the 'ENGLISH' column\n",
        "train_df_bodo['ENGLISH'] = train_df_bodo['ENGLISH'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
        "\n",
        "# Remove punctuation for the 'BODO' column\n",
        "train_df_bodo['BODO'] = train_df_bodo['BODO'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
        "\n",
        "# Remove extra whitespace for the 'ENGLISH' column\n",
        "train_df_bodo['ENGLISH'] = train_df_bodo['ENGLISH'].apply(lambda x: re.sub(r'\\s+', ' ', x.strip()))\n",
        "\n",
        "# Remove extra whitespace for the 'BODO' column\n",
        "train_df_bodo['BODO'] = train_df_bodo['BODO'].apply(lambda x: re.sub(r'\\s+', ' ', x.strip()))\n",
        "\n",
        "# Remove rows with empty values\n",
        "train_df_bodo.replace('', np.nan, inplace=True)\n",
        "train_df_bodo.dropna(subset=['ENGLISH', 'BODO'], inplace=True)\n",
        "\n",
        "# Save the cleaned Bodo data to a new CSV file\n",
        "train_df_bodo.to_csv('bodo.csv', columns=['ENGLISH', 'BODO'], index=False)\n"
      ],
      "metadata": {
        "id": "b7xMb4rLLCBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "4ywcricVLE_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the English to Bodo dataset into training, testing, and validation sets\n",
        "train_data_bodo, temp_data_bodo = train_test_split(train_df_bodo, test_size=0.3, random_state=42)\n",
        "val_data_bodo, test_data_bodo = train_test_split(temp_data_bodo, test_size=0.17, random_state=42)  # 0.17 * (0.7 / 0.3) = 0.15\n",
        "\n",
        "# Save the training, validation, and testing data to separate CSV files for Bodo\n",
        "train_data_bodo.to_csv('trbodo.csv', columns=['ENGLISH', 'BODO'], index=False)\n",
        "val_data_bodo.to_csv('vbodo.csv', columns=['ENGLISH', 'BODO'], index=False)\n",
        "test_data_bodo.to_csv('tsbodo.csv', columns=['ENGLISH', 'BODO'], index=False)\n",
        "\n",
        "# Split the English to Nepali dataset into training, testing, and validation sets\n",
        "train_data_nepali, temp_data_nepali = train_test_split(train_df_nepali, test_size=0.3, random_state=42)\n",
        "val_data_nepali, test_data_nepali = train_test_split(temp_data_nepali, test_size=0.17, random_state=42)  # 0.17 * (0.7 / 0.3) = 0.15\n",
        "\n",
        "# Save the training, validation, and testing data to separate CSV files for Nepali\n",
        "train_data_nepali.to_csv('trnepali.csv', columns=['ENGLISH', 'NEPALI'], index=False)\n",
        "val_data_nepali.to_csv('vnepali.csv', columns=['ENGLISH', 'NEPALI'], index=False)\n",
        "test_data_nepali.to_csv('tenepali.csv', columns=['ENGLISH', 'NEPALI'], index=False)\n",
        "\n",
        "# Split the English to Khasi dataset into training, testing, and validation sets\n",
        "train_data_khasi, temp_data_khasi = train_test_split(train_df_khasi, test_size=0.3, random_state=42)\n",
        "val_data_khasi, test_data_khasi = train_test_split(temp_data_khasi, test_size=0.17, random_state=42)  # 0.17 * (0.7 / 0.3) = 0.15\n",
        "\n",
        "# Save the training, validation, and testing data to separate CSV files for Khasi\n",
        "train_data_khasi.to_csv('trkhasi.csv', columns=['ENGLISH', 'KHASI'], index=False)\n",
        "val_data_khasi.to_csv('vkhasi.csv', columns=['ENGLISH', 'KHASI'], index=False)\n",
        "test_data_khasi.to_csv('tkhasi.csv', columns=['ENGLISH', 'KHASI'], index=False)\n",
        "\n",
        "# Split the English to Manipuri dataset into training, testing, and validation sets\n",
        "train_data_manipuri, temp_data_manipuri = train_test_split(train_df_manipuri, test_size=0.3, random_state=42)\n",
        "val_data_manipuri, test_data_manipuri = train_test_split(temp_data_manipuri, test_size=0.17, random_state=42)  # 0.17 * (0.7 / 0.3) = 0.15\n",
        "\n",
        "# Save the training, validation, and testing data to separate CSV files for Manipuri\n",
        "train_data_manipuri.to_csv('trmanipuri.csv', columns=['ENGLISH', 'MANIPURI'], index=False)\n",
        "val_data_manipuri.to_csv('vmanipuri.csv', columns=['ENGLISH', 'MANIPURI'], index=False)\n",
        "test_data_manipuri.to_csv('tmanipuri.csv', columns=['ENGLISH', 'MANIPURI'], index=False)\n",
        "\n",
        "# Split the English to Mizo dataset into training, testing, and validation sets\n",
        "train_data_mizo, temp_data_mizo = train_test_split(train_df_mizo, test_size=0.3, random_state=42)\n",
        "val_data_mizo, test_data_mizo = train_test_split(temp_data_mizo, test_size=0.17, random_state=42)  # 0.17 * (0.7 / 0.3) = 0.15\n",
        "\n",
        "# Save the training, validation, and testing data to separate CSV files for Mizo\n",
        "train_data_mizo.to_csv('trmizo.csv', columns=['ENGLISH', 'MIZO'], index=False)\n",
        "val_data_mizo.to_csv('vmizo.csv', columns=['ENGLISH', 'MIZO'], index=False)\n",
        "test_data_mizo.to_csv('tmizo.csv', columns=['ENGLISH', 'MIZO'], index=False)\n",
        "\n",
        "# Split the English to Assamese dataset into training, testing, and validation sets\n",
        "train_data_assamese, temp_data_assamese = train_test_split(train_df_assamese, test_size=0.3, random_state=42)\n",
        "val_data_assamese, test_data_assamese = train_test_split(temp_data_assamese, test_size=0.17, random_state=42)  # 0.17 * (0.7 / 0.3) = 0.15\n",
        "\n",
        "# Save the training, validation, and testing data to separate CSV files for Assamese\n",
        "train_data_assamese.to_csv('trassamese.csv', columns=['ENGLISH', 'ASSAMESE'], index=False)\n",
        "val_data_assamese.to_csv('vassamese.csv', columns=['ENGLISH', 'ASSAMESE'], index=False)\n",
        "test_data_assamese.to_csv('tassamese.csv', columns=['ENGLISH', 'ASSAMESE'], index=False)\n"
      ],
      "metadata": {
        "id": "2dB80x8eLGWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate English to Bodo dataset\n",
        "eng_b = train_df_bodo['ENGLISH']\n",
        "brx = train_df_bodo['BODO']\n",
        "\n",
        "# Separate English to Nepali dataset\n",
        "eng_n = train_df_nepali['ENGLISH']\n",
        "npi = train_df_nepali['NEPALI']\n",
        "\n",
        "# Separate English to Khasi dataset\n",
        "eng_khasi = train_df_khasi['ENGLISH']\n",
        "khasi = train_df_khasi['KHASI']\n",
        "\n",
        "# Separate English to Manipuri dataset\n",
        "eng_manipuri = train_df_manipuri['ENGLISH']\n",
        "manipuri = train_df_manipuri['MANIPURI']\n",
        "\n",
        "# Separate English to Mizo dataset\n",
        "eng_mizo = train_df_mizo['ENGLISH']\n",
        "mizo = train_df_mizo['MIZO']\n",
        "\n",
        "# Separate English to Assamese dataset\n",
        "eng_assamese = train_df_assamese['ENGLISH']\n",
        "assamese = train_df_assamese['ASSAMESE']\n"
      ],
      "metadata": {
        "id": "90xlFb5_LNn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng_b = eng_b.apply(lambda x: \"<SOS> \" + str(x) + \" <EOS>\")\n",
        "brx = brx.apply(lambda x: \"<SOS> \" + str(x) + \" <EOS>\")\n",
        "filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
        "oov_token = '<unk>'\n",
        "\n",
        "# Use correct variable names in tokenizers\n",
        "eng_b_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)\n",
        "brx_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)\n",
        "eng_b_tokenizer.fit_on_texts(eng_b)\n",
        "brx_tokenizer.fit_on_texts(brx)\n",
        "inputs_bodo = eng_b_tokenizer.texts_to_sequences(eng_b)\n",
        "targets_bodo = brx_tokenizer.texts_to_sequences(brx)\n",
        "\n",
        "# Print tokenizers\n",
        "print(eng_b_tokenizer)\n",
        "print(brx_tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFtrSk_qLOyw",
        "outputId": "cbeda803-9efd-4ccf-d065-89505cd33bfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.src.preprocessing.text.Tokenizer object at 0x7967e8f98490>\n",
            "<keras.src.preprocessing.text.Tokenizer object at 0x7967e8f98430>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eng_n = eng_n.apply(lambda x: \"<SOS> \" + str(x) + \" <EOS>\")\n",
        "npi = npi.apply(lambda x: \"<SOS> \" + str(x) + \" <EOS>\")\n",
        "filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
        "oov_token = '<unk>'\n",
        "\n",
        "# Use correct variable names in tokenizers\n",
        "eng_n_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)\n",
        "npi_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)\n",
        "eng_n_tokenizer.fit_on_texts(eng_n)\n",
        "npi_tokenizer.fit_on_texts(npi)\n",
        "inputs_nepali = eng_b_tokenizer.texts_to_sequences(eng_n)\n",
        "targets_nepali = brx_tokenizer.texts_to_sequences(npi)\n",
        "\n",
        "# Print tokenizers\n",
        "print(eng_n_tokenizer)\n",
        "print(npi_tokenizer)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfnMds9ULQZN",
        "outputId": "4d6eb666-7661-4480-804f-cb353cead642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.src.preprocessing.text.Tokenizer object at 0x7967e8fa0bb0>\n",
            "<keras.src.preprocessing.text.Tokenizer object at 0x7967e8fa1390>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess Khasi dataset\n",
        "eng_khasi = eng_khasi.apply(lambda x: \"<SOS> \" + str(x) + \" <EOS>\")\n",
        "khasi = khasi.apply(lambda x: \"<SOS> \" + str(x) + \" <EOS>\")\n",
        "eng_khasi_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)\n",
        "khasi_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)\n",
        "eng_khasi_tokenizer.fit_on_texts(eng_khasi)\n",
        "khasi_tokenizer.fit_on_texts(khasi)\n",
        "inputs_khasi = eng_khasi_tokenizer.texts_to_sequences(eng_khasi)\n",
        "targets_khasi = khasi_tokenizer.texts_to_sequences(khasi)\n",
        "\n",
        "# Print tokenizers for Khasi\n",
        "print(eng_khasi_tokenizer)\n",
        "print(khasi_tokenizer)\n",
        "\n",
        "# Preprocess Manipuri dataset\n",
        "eng_manipuri = eng_manipuri.apply(lambda x: \"<SOS> \" + str(x) + \" <EOS>\")\n",
        "manipuri = manipuri.apply(lambda x: \"<SOS> \" + str(x) + \" <EOS>\")\n",
        "eng_manipuri_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)\n",
        "manipuri_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)\n",
        "eng_manipuri_tokenizer.fit_on_texts(eng_manipuri)\n",
        "manipuri_tokenizer.fit_on_texts(manipuri)\n",
        "inputs_manipuri = eng_manipuri_tokenizer.texts_to_sequences(eng_manipuri)\n",
        "targets_manipuri = manipuri_tokenizer.texts_to_sequences(manipuri)\n",
        "\n",
        "# Print tokenizers for Manipuri\n",
        "print(eng_manipuri_tokenizer)\n",
        "print(manipuri_tokenizer)\n",
        "\n",
        "# Preprocess Mizo dataset\n",
        "eng_mizo = eng_mizo.apply(lambda x: \"<SOS> \" + str(x) + \" <EOS>\")\n",
        "mizo = mizo.apply(lambda x: \"<SOS> \" + str(x) + \" <EOS>\")\n",
        "eng_mizo_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)\n",
        "mizo_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)\n",
        "eng_mizo_tokenizer.fit_on_texts(eng_mizo)\n",
        "mizo_tokenizer.fit_on_texts(mizo)\n",
        "inputs_mizo = eng_mizo_tokenizer.texts_to_sequences(eng_mizo)\n",
        "targets_mizo = mizo_tokenizer.texts_to_sequences(mizo)\n",
        "\n",
        "# Print tokenizers for Mizo\n",
        "print(eng_mizo_tokenizer)\n",
        "print(mizo_tokenizer)\n",
        "\n",
        "# Preprocess Assamese dataset\n",
        "eng_assamese = eng_assamese.apply(lambda x: \"<SOS> \" + str(x) + \" <EOS>\")\n",
        "assamese = assamese.apply(lambda x: \"<SOS> \" + str(x) + \" <EOS>\")\n",
        "eng_assamese_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)\n",
        "assamese_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)\n",
        "eng_assamese_tokenizer.fit_on_texts(eng_assamese)\n",
        "assamese_tokenizer.fit_on_texts(assamese)\n",
        "inputs_assamese = eng_assamese_tokenizer.texts_to_sequences(eng_assamese)\n",
        "targets_assamese = assamese_tokenizer.texts_to_sequences(assamese)\n",
        "\n",
        "# Print tokenizers for Assamese\n",
        "print(eng_assamese_tokenizer)\n",
        "print(assamese_tokenizer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JaJcZZULRyB",
        "outputId": "322f454c-6c48-4e9e-a6e2-7647d570e7fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.src.preprocessing.text.Tokenizer object at 0x7967e8fa1e40>\n",
            "<keras.src.preprocessing.text.Tokenizer object at 0x7967e8fa3b50>\n",
            "<keras.src.preprocessing.text.Tokenizer object at 0x7967e8fa2770>\n",
            "<keras.src.preprocessing.text.Tokenizer object at 0x7967e8f9a080>\n",
            "<keras.src.preprocessing.text.Tokenizer object at 0x7967e9c0f7f0>\n",
            "<keras.src.preprocessing.text.Tokenizer object at 0x7967e9c0f970>\n",
            "<keras.src.preprocessing.text.Tokenizer object at 0x7967e8f9a260>\n",
            "<keras.src.preprocessing.text.Tokenizer object at 0x7967e8f99d80>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Collect all English texts from the different datasets\n",
        "all_eng_texts = pd.concat([eng_b, eng_n, eng_khasi, eng_manipuri, eng_mizo, eng_assamese], ignore_index=True)\n",
        "\n",
        "# Create a new tokenizer and fit it on the combined English texts\n",
        "merged_eng_tokenizer = Tokenizer(filters=filters, oov_token=oov_token)\n",
        "merged_eng_tokenizer.fit_on_texts(all_eng_texts)\n",
        "\n",
        "# Print the merged English tokenizer\n",
        "print(merged_eng_tokenizer)\n",
        "\n",
        "# Optionally, save the tokenizer if needed\n",
        "import pickle\n",
        "with open('merged_eng_tokenizer.pkl', 'wb') as f:\n",
        "    pickle.dump(merged_eng_tokenizer, f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTatkrgVLTa4",
        "outputId": "39da4003-b43b-47e4-e28c-ca3223ada763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.src.preprocessing.text.Tokenizer object at 0x7967e9c0eda0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ENCODER_VOCAB = len(merged_eng_tokenizer.word_index) + 1\n",
        "DECODER_B_VOCAB = len(brx_tokenizer.word_index) + 1\n",
        "print(ENCODER_VOCAB, DECODER_B_VOCAB)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1reyWRNLVvd",
        "outputId": "e2b9d548-aa4c-47f1-81d8-85966b894438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130870 200240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "DECODER_A_VOCAB = len(assamese_tokenizer.word_index) + 1\n",
        "DECODER_B_VOCAB = len(brx_tokenizer.word_index) + 1\n",
        "DECODER_N_VOCAB = len(npi_tokenizer.word_index) + 1\n",
        "DECODER_K_VOCAB = len(khasi_tokenizer.word_index) + 1\n",
        "DECODER_MI_VOCAB = len(mizo_tokenizer.word_index) + 1\n",
        "DECODER_MA_VOCAB = len(manipuri_tokenizer.word_index) + 1\n"
      ],
      "metadata": {
        "id": "c9TFtzGyLWUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calculate max lengths among sequences\n",
        "max_length_bodo_encoder = max(len(seq) for seq in inputs_bodo)\n",
        "max_length_bodo_decoder = max(len(seq) for seq in targets_bodo)\n",
        "\n",
        "\n",
        "# Calculate max lengths among sequences\n",
        "max_length_nepali_encoder = max(len(seq) for seq in inputs_nepali)\n",
        "max_length_nepali_decoder = max(len(seq) for seq in targets_nepali)\n"
      ],
      "metadata": {
        "id": "QwNEaTvgLdd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate max lengths among sequences for all languages\n",
        "\n",
        "# Bodo\n",
        "max_length_bodo_encoder = max(len(seq) for seq in inputs_bodo)\n",
        "\n",
        "# Nepali\n",
        "max_length_nepali_encoder = max(len(seq) for seq in inputs_nepali)\n",
        "\n",
        "# Khasi\n",
        "max_length_khasi_encoder = max(len(seq) for seq in inputs_khasi)\n",
        "\n",
        "# Manipuri\n",
        "max_length_manipuri_encoder = max(len(seq) for seq in inputs_manipuri)\n",
        "\n",
        "# Mizo\n",
        "max_length_mizo_encoder = max(len(seq) for seq in inputs_mizo)\n",
        "\n",
        "# Assamese\n",
        "max_length_assamese_encoder = max(len(seq) for seq in inputs_assamese)\n",
        "\n",
        "# Find the overall maximum length for the shared encoder\n",
        "max_length_encoder = max(\n",
        "    max_length_bodo_encoder,\n",
        "    max_length_nepali_encoder,\n",
        "    max_length_khasi_encoder,\n",
        "    max_length_manipuri_encoder,\n",
        "    max_length_mizo_encoder,\n",
        "    max_length_assamese_encoder\n",
        ")\n",
        "\n",
        "# Print maximum lengths for the shared encoder\n",
        "print(\"Max length for shared encoder:\", max_length_encoder)\n",
        "\n",
        "# Calculate max lengths among sequences for decoders\n",
        "# Bodo\n",
        "max_length_bodo_decoder = max(len(seq) for seq in targets_bodo)\n",
        "# Nepali\n",
        "max_length_nepali_decoder = max(len(seq) for seq in targets_nepali)\n",
        "# Khasi\n",
        "max_length_khasi_decoder = max(len(seq) for seq in targets_khasi)\n",
        "# Manipuri\n",
        "max_length_manipuri_decoder = max(len(seq) for seq in targets_manipuri)\n",
        "# Mizo\n",
        "max_length_mizo_decoder = max(len(seq) for seq in targets_mizo)\n",
        "# Assamese\n",
        "max_length_assamese_decoder = max(len(seq) for seq in targets_assamese)\n",
        "\n",
        "# Find the overall maximum length for the decoders\n",
        "max_length_decoder = max(\n",
        "    max_length_bodo_decoder,\n",
        "    max_length_nepali_decoder,\n",
        "    max_length_khasi_decoder,\n",
        "    max_length_manipuri_decoder,\n",
        "    max_length_mizo_decoder,\n",
        "    max_length_assamese_decoder\n",
        ")\n",
        "\n",
        "# Print maximum lengths for the decoders\n",
        "print(\"Max length for all decoders:\", max_length_decoder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1juocrfLeiE",
        "outputId": "bec0b36d-5eaf-4dab-c382-3b414b2dac49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max length for shared encoder: 1062\n",
            "Max length for all decoders: 1541\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Pad sequences to a common length for each language\n",
        "def pad_and_convert(inputs, targets, max_length_encoder, max_length_decoder):\n",
        "    inputs_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "        inputs, maxlen=max_length_encoder, padding='post', truncating='post'\n",
        "    )\n",
        "    targets_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "        targets, maxlen=max_length_decoder, padding='post', truncating='post'\n",
        "    )\n",
        "    inputs_tensor = tf.convert_to_tensor(inputs_padded)\n",
        "    targets_tensor = tf.convert_to_tensor(targets_padded)\n",
        "    return inputs_tensor, targets_tensor\n",
        "\n",
        "# Example for Nepali\n",
        "inputs_nepali, targets_nepali = pad_and_convert(inputs_nepali, targets_nepali, max_length_nepali_encoder, max_length_nepali_decoder)\n",
        "\n",
        "# Similarly, pad and convert for Bodo\n",
        "inputs_bodo, targets_bodo = pad_and_convert(inputs_bodo, targets_bodo, max_length_encoder, max_length_bodo_decoder)\n",
        "\n",
        "# Similarly, pad and convert for Khasi\n",
        "inputs_khasi, targets_khasi = pad_and_convert(inputs_khasi, targets_khasi, max_length_encoder, max_length_khasi_decoder)\n",
        "\n",
        "# Similarly, pad and convert for Manipuri\n",
        "inputs_manipuri, targets_manipuri = pad_and_convert(inputs_manipuri, targets_manipuri, max_length_encoder, max_length_manipuri_decoder)\n",
        "\n",
        "# Similarly, pad and convert for Mizo\n",
        "inputs_mizo, targets_mizo = pad_and_convert(inputs_mizo, targets_mizo, max_length_encoder, max_length_mizo_decoder)\n",
        "\n",
        "# Similarly, pad and convert for Assamese\n",
        "inputs_assamese, targets_assamese = pad_and_convert(inputs_assamese, targets_assamese, max_length_encoder, max_length_assamese_decoder)\n"
      ],
      "metadata": {
        "id": "YgCczICOLgA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs_bodo)\n",
        "print(targets_bodo)\n",
        "print(inputs_nepali)\n",
        "print(targets_nepali)\n",
        "print(\"Inputs Khasi:\", inputs_khasi)\n",
        "print(\"Targets Khasi:\", targets_khasi)\n",
        "print(\"Inputs Manipuri:\", inputs_manipuri)\n",
        "print(\"Targets Manipuri:\", targets_manipuri)\n",
        "print(\"Inputs Mizo:\", inputs_mizo)\n",
        "print(\"Targets Mizo:\", targets_mizo)\n",
        "print(\"Inputs Assamese:\", inputs_assamese)\n",
        "print(\"Targets Assamese:\", targets_assamese)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFAEugA8Ls2c",
        "outputId": "0c8fdaf8-5cb5-40e9-b692-fc1a790bdb54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[    3   206   765 ...     0     0     0]\n",
            " [    3   300   106 ...     0     0     0]\n",
            " [    3   619  2024 ...     0     0     0]\n",
            " ...\n",
            " [    3 65871  1844 ...     0     0     0]\n",
            " [    3 65872  1759 ...     0     0     0]\n",
            " [    3  5907 18842 ...     0     0     0]], shape=(116906, 1062), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[     2    228   9381 ...      0      0      0]\n",
            " [     2      6    254 ...      0      0      0]\n",
            " [     2    943      7 ...      0      0      0]\n",
            " ...\n",
            " [     2 200234   3267 ...      0      0      0]\n",
            " [     2 200236   3056 ...      0      0      0]\n",
            " [     2  28110  75403 ...      0      0      0]], shape=(116906, 125), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[   3   13 1438 ...    0    0    0]\n",
            " [   3   13 1438 ...    0    0    0]\n",
            " [   3 6682  179 ...    0    0    0]\n",
            " ...\n",
            " [   3 1671    2 ...    0    0    0]\n",
            " [   3 2092  672 ...    0    0    0]\n",
            " [   3 3071    2 ...    0    0    0]], shape=(151810, 500), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[     2      1      1 ...      0      0      0]\n",
            " [     2      1      1 ...      0      0      0]\n",
            " [     2      1      1 ...      0      0      0]\n",
            " ...\n",
            " [     2      1  72094 ...      0      0      0]\n",
            " [     2      1  42063 ...      0      0      0]\n",
            " [     2 199597      1 ...      0      0      0]], shape=(151810, 416), dtype=int32)\n",
            "Inputs Khasi: tf.Tensor(\n",
            "[[   5    3   94 ...    0    0    0]\n",
            " [   5   13   35 ...    0    0    0]\n",
            " [   5   33  113 ...    0    0    0]\n",
            " ...\n",
            " [   5    3 1575 ...    0    0    0]\n",
            " [   5    3   66 ...    0    0    0]\n",
            " [   5   91   15 ...    0    0    0]], shape=(26000, 1062), dtype=int32)\n",
            "Targets Khasi: tf.Tensor(\n",
            "[[  8 314 121 ...   0   0   0]\n",
            " [  8  13  44 ...   0   0   0]\n",
            " [  8  34   3 ...   0   0   0]\n",
            " ...\n",
            " [  8 135   2 ...   0   0   0]\n",
            " [  8  30   6 ...   0   0   0]\n",
            " [  8   7  42 ...   0   0   0]], shape=(26000, 1541), dtype=int32)\n",
            "Inputs Manipuri: tf.Tensor(\n",
            "[[    3 13991  2085 ...     0     0     0]\n",
            " [    3   186   538 ...     0     0     0]\n",
            " [    3   822 19778 ...     0     0     0]\n",
            " ...\n",
            " [    3    91 12983 ...     0     0     0]\n",
            " [    3  4042  8211 ...     0     0     0]\n",
            " [    3    15    37 ...     0     0     0]], shape=(60135, 1062), dtype=int32)\n",
            "Targets Manipuri: tf.Tensor(\n",
            "[[    2   889 14707 ...     0     0     0]\n",
            " [    2  1496   446 ...     0     0     0]\n",
            " [    2 10693 18331 ...     0     0     0]\n",
            " ...\n",
            " [    2 32718   766 ...     0     0     0]\n",
            " [    2 33156 16961 ...     0     0     0]\n",
            " [    2    62  2501 ...     0     0     0]], shape=(60135, 77), dtype=int32)\n",
            "Inputs Mizo: tf.Tensor(\n",
            "[[   3   79   16 ...    0    0    0]\n",
            " [   3    7 1348 ...    0    0    0]\n",
            " [   3  141  171 ...    0    0    0]\n",
            " ...\n",
            " [   3   13  385 ...    0    0    0]\n",
            " [   3  118   67 ...    0    0    0]\n",
            " [   3   44  386 ...    0    0    0]], shape=(53485, 1062), dtype=int32)\n",
            "Targets Mizo: tf.Tensor(\n",
            "[[   3  289    2 ...    0    0    0]\n",
            " [   3    2  454 ...    0    0    0]\n",
            " [   3  163   35 ...    0    0    0]\n",
            " ...\n",
            " [   3  338   47 ...    0    0    0]\n",
            " [   3  571 2086 ...    0    0    0]\n",
            " [   3 4594    2 ...    0    0    0]], shape=(53485, 195), dtype=int32)\n",
            "Inputs Assamese: tf.Tensor(\n",
            "[[   2 6549   83 ...    0    0    0]\n",
            " [   2 1618   24 ...    0    0    0]\n",
            " [   2  299  280 ...    0    0    0]\n",
            " ...\n",
            " [   2   28   17 ...    0    0    0]\n",
            " [   2   25   37 ...    0    0    0]\n",
            " [   2   33 1571 ...    0    0    0]], shape=(141233, 1062), dtype=int32)\n",
            "Targets Assamese: tf.Tensor(\n",
            "[[    2  5590  1615 ...     0     0     0]\n",
            " [    2  2060  2224 ...     0     0     0]\n",
            " [    2  1426  1512 ...     0     0     0]\n",
            " ...\n",
            " [    2    90    31 ...     0     0     0]\n",
            " [    2  3535  5905 ...     0     0     0]\n",
            " [    2 90706     7 ...     0     0     0]], shape=(141233, 1300), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataset for English to Bodo\n",
        "bodo_dataset = tf.data.Dataset.from_tensor_slices((inputs_bodo, targets_bodo, np.ones_like(inputs_bodo))).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "# Create a dataset for English to Nepali\n",
        "nepali_dataset = tf.data.Dataset.from_tensor_slices((inputs_nepali, targets_nepali, np.ones_like(inputs_nepali) * 2)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "# Create a dataset for English to Khasi\n",
        "khasi_dataset = tf.data.Dataset.from_tensor_slices((inputs_khasi, targets_khasi, np.ones_like(inputs_khasi) * 3)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "# Create a dataset for English to Manipuri\n",
        "manipuri_dataset = tf.data.Dataset.from_tensor_slices((inputs_manipuri, targets_manipuri, np.ones_like(inputs_manipuri) * 4)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "# Create a dataset for English to Mizo\n",
        "mizo_dataset = tf.data.Dataset.from_tensor_slices((inputs_mizo, targets_mizo, np.ones_like(inputs_mizo) * 5)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "# Create a dataset for English to Assamese\n",
        "assamese_dataset = tf.data.Dataset.from_tensor_slices((inputs_assamese, targets_assamese, np.ones_like(inputs_assamese) * 6)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "9L0ONF74LxYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_angles(position, i, d_model, lang_id):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "    return position * angle_rates + lang_id\n",
        "\n",
        "def positional_encoding(position, d_model, lang_id):\n",
        "    angle_rads = get_angles(\n",
        "        np.arange(position)[:, np.newaxis],\n",
        "        np.arange(d_model)[np.newaxis, :],\n",
        "        d_model,\n",
        "        lang_id\n",
        "    )\n",
        "\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "\n",
        "\n",
        "def create_padding_mask(seq):\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "def create_look_ahead_mask(size):\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return mask\n",
        "\n",
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
        "\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
        "\n",
        "    output = tf.matmul(attention_weights, v)\n",
        "    return output, attention_weights\n"
      ],
      "metadata": {
        "id": "V5ZpS0c7L1zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, v, k, q, mask, lang_id):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "\n",
        "        # Apply language-specific embeddings\n",
        "        q = tf.concat([q, tf.one_hot(lang_id, depth=2)], axis=-1)\n",
        "        k = tf.concat([k, tf.one_hot(lang_id, depth=2)], axis=-1)\n",
        "        v = tf.concat([v, tf.one_hot(lang_id, depth=2)], axis=-1)\n",
        "\n",
        "        q = self.wq(q)\n",
        "        k = self.wk(k)\n",
        "        v = self.wv(v)\n",
        "\n",
        "        q = self.split_heads(q, batch_size)\n",
        "        k = self.split_heads(k, batch_size)\n",
        "        v = self.split_heads(v, batch_size)\n",
        "\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "            q, k, v, mask)\n",
        "\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
        "        output = self.dense(concat_attention)\n",
        "\n",
        "        return output, attention_weights\n",
        "\n",
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "    return tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(dff, activation='relu'),\n",
        "        tf.keras.layers.Dense(d_model)\n",
        "    ])"
      ],
      "metadata": {
        "id": "RWsMdpw2L2-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        # Define multi-head attention layers for each language\n",
        "        self.mha = {\n",
        "            'bodo': MultiHeadAttention(d_model, num_heads),\n",
        "            'nepali': MultiHeadAttention(d_model, num_heads),\n",
        "            'khasi': MultiHeadAttention(d_model, num_heads),\n",
        "            'manipuri': MultiHeadAttention(d_model, num_heads),\n",
        "            'mizo': MultiHeadAttention(d_model, num_heads),\n",
        "            'assamese': MultiHeadAttention(d_model, num_heads)\n",
        "        }\n",
        "\n",
        "        # Define feed-forward networks for each language\n",
        "        self.ffn = {\n",
        "            'bodo': point_wise_feed_forward_network(d_model, dff),\n",
        "            'nepali': point_wise_feed_forward_network(d_model, dff),\n",
        "            'khasi': point_wise_feed_forward_network(d_model, dff),\n",
        "            'manipuri': point_wise_feed_forward_network(d_model, dff),\n",
        "            'mizo': point_wise_feed_forward_network(d_model, dff),\n",
        "            'assamese': point_wise_feed_forward_network(d_model, dff)\n",
        "        }\n",
        "\n",
        "        # Define layer normalization layers for each language\n",
        "        self.layernorm1 = {\n",
        "            'bodo': tf.keras.layers.LayerNormalization(epsilon=1e-6),\n",
        "            'nepali': tf.keras.layers.LayerNormalization(epsilon=1e-6),\n",
        "            'khasi': tf.keras.layers.LayerNormalization(epsilon=1e-6),\n",
        "            'manipuri': tf.keras.layers.LayerNormalization(epsilon=1e-6),\n",
        "            'mizo': tf.keras.layers.LayerNormalization(epsilon=1e-6),\n",
        "            'assamese': tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        }\n",
        "        self.layernorm2 = {\n",
        "            'bodo': tf.keras.layers.LayerNormalization(epsilon=1e-6),\n",
        "            'nepali': tf.keras.layers.LayerNormalization(epsilon=1e-6),\n",
        "            'khasi': tf.keras.layers.LayerNormalization(epsilon=1e-6),\n",
        "            'manipuri': tf.keras.layers.LayerNormalization(epsilon=1e-6),\n",
        "            'mizo': tf.keras.layers.LayerNormalization(epsilon=1e-6),\n",
        "            'assamese': tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        }\n",
        "\n",
        "        # Define dropout layers\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, training, masks):\n",
        "        outputs = {}\n",
        "\n",
        "        # Process each language\n",
        "        for lang in ['bodo', 'nepali', 'khasi', 'manipuri', 'mizo', 'assamese']:\n",
        "            attn_output, _ = self.mha[lang](x[lang], x[lang], x[lang], masks[lang])\n",
        "            attn_output = self.dropout1(attn_output, training=training)\n",
        "            out1 = self.layernorm1[lang](x[lang] + attn_output)\n",
        "\n",
        "            ffn_output = self.ffn[lang](out1)\n",
        "            ffn_output = self.dropout2(ffn_output, training=training)\n",
        "            outputs[lang] = self.layernorm2[lang](out1 + ffn_output)\n",
        "\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "jdJQNiZQL8dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        # Define MultiHeadAttention and feed-forward networks for each language\n",
        "        self.mha1_bodo = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2_bodo = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn_bodo = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.mha1_nepali = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2_nepali = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn_nepali = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.mha1_khasi = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2_khasi = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn_khasi = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.mha1_manipuri = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2_manipuri = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn_manipuri = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.mha1_mizo = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2_mizo = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn_mizo = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.mha1_assamese = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2_assamese = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn_assamese = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        # Define LayerNormalization and Dropout layers for each language\n",
        "        self.layernorm1_bodo = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2_bodo = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3_bodo = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.layernorm1_nepali = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2_nepali = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3_nepali = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.layernorm1_khasi = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2_khasi = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3_khasi = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.layernorm1_manipuri = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2_manipuri = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3_manipuri = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.layernorm1_mizo = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2_mizo = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3_mizo = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.layernorm1_assamese = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2_assamese = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3_assamese = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask, language):\n",
        "        if language == 'bodo':\n",
        "            mha1 = self.mha1_bodo\n",
        "            mha2 = self.mha2_bodo\n",
        "            ffn = self.ffn_bodo\n",
        "            layernorm1 = self.layernorm1_bodo\n",
        "            layernorm2 = self.layernorm2_bodo\n",
        "            layernorm3 = self.layernorm3_bodo\n",
        "\n",
        "        elif language == 'nepali':\n",
        "            mha1 = self.mha1_nepali\n",
        "            mha2 = self.mha2_nepali\n",
        "            ffn = self.ffn_nepali\n",
        "            layernorm1 = self.layernorm1_nepali\n",
        "            layernorm2 = self.layernorm2_nepali\n",
        "            layernorm3 = self.layernorm3_nepali\n",
        "\n",
        "        elif language == 'khasi':\n",
        "            mha1 = self.mha1_khasi\n",
        "            mha2 = self.mha2_khasi\n",
        "            ffn = self.ffn_khasi\n",
        "            layernorm1 = self.layernorm1_khasi\n",
        "            layernorm2 = self.layernorm2_khasi\n",
        "            layernorm3 = self.layernorm3_khasi\n",
        "\n",
        "        elif language == 'manipuri':\n",
        "            mha1 = self.mha1_manipuri\n",
        "            mha2 = self.mha2_manipuri\n",
        "            ffn = self.ffn_manipuri\n",
        "            layernorm1 = self.layernorm1_manipuri\n",
        "            layernorm2 = self.layernorm2_manipuri\n",
        "            layernorm3 = self.layernorm3_manipuri\n",
        "\n",
        "        elif language == 'mizo':\n",
        "            mha1 = self.mha1_mizo\n",
        "            mha2 = self.mha2_mizo\n",
        "            ffn = self.ffn_mizo\n",
        "            layernorm1 = self.layernorm1_mizo\n",
        "            layernorm2 = self.layernorm2_mizo\n",
        "            layernorm3 = self.layernorm3_mizo\n",
        "\n",
        "        elif language == 'assamese':\n",
        "            mha1 = self.mha1_assamese\n",
        "            mha2 = self.mha2_assamese\n",
        "            ffn = self.ffn_assamese\n",
        "            layernorm1 = self.layernorm1_assamese\n",
        "            layernorm2 = self.layernorm2_assamese\n",
        "            layernorm3 = self.layernorm3_assamese\n",
        "\n",
        "        # Self-attention\n",
        "        attn1, attn_weights_block1 = mha1(x, x, x, look_ahead_mask)\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = layernorm1(attn1 + x)\n",
        "\n",
        "        # Cross-attention\n",
        "        attn2, attn_weights_block2 = mha2(enc_output, enc_output, out1, padding_mask)\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = layernorm2(attn2 + out1)\n",
        "\n",
        "        # Feed-forward network\n",
        "        ffn_output = ffn(out2)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = layernorm3(ffn_output + out2)\n",
        "\n",
        "        return out3, attn_weights_block1, attn_weights_block2\n"
      ],
      "metadata": {
        "id": "d4faadK2MHEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class SharedEncoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_english_vocab_size, maximum_position_encoding, rate=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding_english = tf.keras.layers.Embedding(input_english_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
        "\n",
        "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x_english, training, mask_english):\n",
        "        seq_len_english = tf.shape(x_english)[1]\n",
        "\n",
        "        x_english = self.embedding_english(x_english)\n",
        "        x_english *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x_english += self.pos_encoding[:, :seq_len_english, :]\n",
        "\n",
        "        x_english = self.dropout(x_english, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x_english = self.enc_layers[i](x_english, training, mask_english)\n",
        "\n",
        "        return x_english\n"
      ],
      "metadata": {
        "id": "jmWrkGTAMJpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderAssamese(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, target_assamese_vocab_size, maximum_position_encoding, rate=0.1):\n",
        "        super(DecoderAssamese, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding_assamese = tf.keras.layers.Embedding(target_assamese_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "        self.dec_layers_assamese = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x_assamese, enc_output_english, training, look_ahead_mask_assamese, padding_mask_assamese):\n",
        "        seq_len_assamese = tf.shape(x_assamese)[1]\n",
        "        attention_weights_assamese = {}\n",
        "\n",
        "        x_assamese = self.embedding_assamese(x_assamese)\n",
        "        x_assamese *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x_assamese += self.pos_encoding[:, :seq_len_assamese, :]\n",
        "\n",
        "        x_assamese = self.dropout(x_assamese, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x_assamese, block1_assamese, block2_assamese = self.dec_layers_assamese[i](x_assamese, enc_output_english, training, look_ahead_mask_assamese, padding_mask_assamese)\n",
        "\n",
        "            attention_weights_assamese[f'decoder_layer{i+1}_block1'] = block1_assamese\n",
        "            attention_weights_assamese[f'decoder_layer{i+1}_block2'] = block2_assamese\n",
        "\n",
        "        return x_assamese, attention_weights_assamese\n"
      ],
      "metadata": {
        "id": "ElvCyBEoMLGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBodo(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, target_bodo_vocab_size, maximum_position_encoding, rate=0.1):\n",
        "        super(DecoderBodo, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding_bodo = tf.keras.layers.Embedding(target_bodo_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "        self.dec_layers_bodo = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x_bodo, enc_output_english, training, look_ahead_mask_bodo, padding_mask_bodo):\n",
        "        seq_len_bodo = tf.shape(x_bodo)[1]\n",
        "        attention_weights_bodo = {}\n",
        "\n",
        "        x_bodo = self.embedding_bodo(x_bodo)\n",
        "        x_bodo *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x_bodo += self.pos_encoding[:, :seq_len_bodo, :]\n",
        "\n",
        "        x_bodo = self.dropout(x_bodo, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x_bodo, block1_bodo, block2_bodo = self.dec_layers_bodo[i](x_bodo, enc_output_english, training, look_ahead_mask_bodo, padding_mask_bodo)\n",
        "\n",
        "            attention_weights_bodo[f'decoder_layer{i+1}_block1'] = block1_bodo\n",
        "            attention_weights_bodo[f'decoder_layer{i+1}_block2'] = block2_bodo\n",
        "\n",
        "        return x_bodo, attention_weights_bodo\n"
      ],
      "metadata": {
        "id": "uACoDOc0MMcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderKhasi(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, target_khasi_vocab_size, maximum_position_encoding, rate=0.1):\n",
        "        super(DecoderKhasi, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding_khasi = tf.keras.layers.Embedding(target_khasi_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "        self.dec_layers_khasi = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x_khasi, enc_output_english, training, look_ahead_mask_khasi, padding_mask_khasi):\n",
        "        seq_len_khasi = tf.shape(x_khasi)[1]\n",
        "        attention_weights_khasi = {}\n",
        "\n",
        "        x_khasi = self.embedding_khasi(x_khasi)\n",
        "        x_khasi *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x_khasi += self.pos_encoding[:, :seq_len_khasi, :]\n",
        "\n",
        "        x_khasi = self.dropout(x_khasi, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x_khasi, block1_khasi, block2_khasi = self.dec_layers_khasi[i](x_khasi, enc_output_english, training, look_ahead_mask_khasi, padding_mask_khasi)\n",
        "\n",
        "            attention_weights_khasi[f'decoder_layer{i+1}_block1'] = block1_khasi\n",
        "            attention_weights_khasi[f'decoder_layer{i+1}_block2'] = block2_khasi\n",
        "\n",
        "        return x_khasi, attention_weights_khasi\n"
      ],
      "metadata": {
        "id": "Q8fYOAwlMN45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderManipuri(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, target_manipuri_vocab_size, maximum_position_encoding, rate=0.1):\n",
        "        super(DecoderManipuri, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding_manipuri = tf.keras.layers.Embedding(target_manipuri_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "        self.dec_layers_manipuri = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x_manipuri, enc_output_english, training, look_ahead_mask_manipuri, padding_mask_manipuri):\n",
        "        seq_len_manipuri = tf.shape(x_manipuri)[1]\n",
        "        attention_weights_manipuri = {}\n",
        "\n",
        "        x_manipuri = self.embedding_manipuri(x_manipuri)\n",
        "        x_manipuri *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x_manipuri += self.pos_encoding[:, :seq_len_manipuri, :]\n",
        "\n",
        "        x_manipuri = self.dropout(x_manipuri, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x_manipuri, block1_manipuri, block2_manipuri = self.dec_layers_manipuri[i](x_manipuri, enc_output_english, training, look_ahead_mask_manipuri, padding_mask_manipuri)\n",
        "\n",
        "            attention_weights_manipuri[f'decoder_layer{i+1}_block1'] = block1_manipuri\n",
        "            attention_weights_manipuri[f'decoder_layer{i+1}_block2'] = block2_manipuri\n",
        "\n",
        "        return x_manipuri, attention_weights_manipuri\n"
      ],
      "metadata": {
        "id": "2MH6N0YhMPG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderMizo(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, target_mizo_vocab_size, maximum_position_encoding, rate=0.1):\n",
        "        super(DecoderMizo, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding_mizo = tf.keras.layers.Embedding(target_mizo_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "        self.dec_layers_mizo = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x_mizo, enc_output_english, training, look_ahead_mask_mizo, padding_mask_mizo):\n",
        "        seq_len_mizo = tf.shape(x_mizo)[1]\n",
        "        attention_weights_mizo = {}\n",
        "\n",
        "        x_mizo = self.embedding_mizo(x_mizo)\n",
        "        x_mizo *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x_mizo += self.pos_encoding[:, :seq_len_mizo, :]\n",
        "\n",
        "        x_mizo = self.dropout(x_mizo, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x_mizo, block1_mizo, block2_mizo = self.dec_layers_mizo[i](x_mizo, enc_output_english, training, look_ahead_mask_mizo, padding_mask_mizo)\n",
        "\n",
        "            attention_weights_mizo[f'decoder_layer{i+1}_block1'] = block1_mizo\n",
        "            attention_weights_mizo[f'decoder_layer{i+1}_block2'] = block2_mizo\n",
        "\n",
        "        return x_mizo, attention_weights\n"
      ],
      "metadata": {
        "id": "rli5v9trMQvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderNepali(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, target_nepali_vocab_size, maximum_position_encoding, rate=0.1):\n",
        "        super(DecoderNepali, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding_nepali = tf.keras.layers.Embedding(target_nepali_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "        self.dec_layers_nepali = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x_nepali, enc_output_english, training, look_ahead_mask_nepali, padding_mask_nepali):\n",
        "        seq_len_nepali = tf.shape(x_nepali)[1]\n",
        "        attention_weights_nepali = {}\n",
        "\n",
        "        x_nepali = self.embedding_nepali(x_nepali)\n",
        "        x_nepali *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x_nepali += self.pos_encoding[:, :seq_len_nepali, :]\n",
        "\n",
        "        x_nepali = self.dropout(x_nepali, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x_nepali, block1_nepali, block2_nepali = self.dec_layers_nepali[i](x_nepali, enc_output_english, training, look_ahead_mask_nepali, padding_mask_nepali)\n",
        "\n",
        "            attention_weights_nepali[f'decoder_layer{i+1}_block1'] = block1_nepali\n",
        "            attention_weights_nepali[f'decoder_layer{i+1}_block2'] = block2_nepali\n",
        "\n",
        "        return x_nepali, attention_weights_nepali\n"
      ],
      "metadata": {
        "id": "ehdoc6uFMSIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class MultiTransformer(tf.keras.Model):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_sizes, target_vocab_sizes, pe_input, pe_target, rate=0.1):\n",
        "        super(MultiTransformer, self).__init__()\n",
        "\n",
        "        # Define language IDs\n",
        "        lang_ids = {\n",
        "            'bodo': 1,\n",
        "            'nepali': 2,\n",
        "            'khasi': 3,\n",
        "            'manipuri': 4,\n",
        "            'mizo': 5,\n",
        "            'assamese': 6\n",
        "        }\n",
        "\n",
        "        # Embeddings\n",
        "        self.embedding = {\n",
        "            'bodo': tf.keras.layers.Embedding(input_vocab_sizes['bodo'], d_model),\n",
        "            'nepali': tf.keras.layers.Embedding(input_vocab_sizes['nepali'], d_model),\n",
        "            'khasi': tf.keras.layers.Embedding(input_vocab_sizes['khasi'], d_model),\n",
        "            'manipuri': tf.keras.layers.Embedding(input_vocab_sizes['manipuri'], d_model),\n",
        "            'mizo': tf.keras.layers.Embedding(input_vocab_sizes['mizo'], d_model),\n",
        "            'assamese': tf.keras.layers.Embedding(input_vocab_sizes['assamese'], d_model)\n",
        "        }\n",
        "\n",
        "        # Positional Encodings\n",
        "        self.pos_encoding = {\n",
        "            'bodo': positional_encoding(pe_input, d_model, lang_ids['bodo']),\n",
        "            'nepali': positional_encoding(pe_input, d_model, lang_ids['nepali']),\n",
        "            'khasi': positional_encoding(pe_input, d_model, lang_ids['khasi']),\n",
        "            'manipuri': positional_encoding(pe_input, d_model, lang_ids['manipuri']),\n",
        "            'mizo': positional_encoding(pe_input, d_model, lang_ids['mizo']),\n",
        "            'assamese': positional_encoding(pe_input, d_model, lang_ids['assamese'])\n",
        "        }\n",
        "\n",
        "        # Encoder and Decoder Layers\n",
        "        self.enc_layers = {\n",
        "            'bodo': [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)],\n",
        "            'nepali': [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)],\n",
        "            'khasi': [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)],\n",
        "            'manipuri': [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)],\n",
        "            'mizo': [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)],\n",
        "            'assamese': [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "        }\n",
        "\n",
        "        self.dec_layers = {\n",
        "            'bodo': [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)],\n",
        "            'nepali': [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)],\n",
        "            'khasi': [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)],\n",
        "            'manipuri': [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)],\n",
        "            'mizo': [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)],\n",
        "            'assamese': [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "        }\n",
        "\n",
        "        # Final Dense Layers\n",
        "        self.final_layers = {\n",
        "            'bodo': tf.keras.layers.Dense(target_vocab_sizes['bodo']),\n",
        "            'nepali': tf.keras.layers.Dense(target_vocab_sizes['nepali']),\n",
        "            'khasi': tf.keras.layers.Dense(target_vocab_sizes['khasi']),\n",
        "            'manipuri': tf.keras.layers.Dense(target_vocab_sizes['manipuri']),\n",
        "            'mizo': tf.keras.layers.Dense(target_vocab_sizes['mizo']),\n",
        "            'assamese': tf.keras.layers.Dense(target_vocab_sizes['assamese'])\n",
        "        }\n",
        "\n",
        "    def call(self, inputs, targets, training, masks):\n",
        "        enc_outputs = {}\n",
        "        for lang in ['bodo', 'nepali', 'khasi', 'manipuri', 'mizo', 'assamese']:\n",
        "            enc_inputs = inputs[lang]\n",
        "            enc_outputs[lang] = self.encoder(enc_inputs, lang, training, masks[lang]['enc_padding_mask'])\n",
        "\n",
        "        dec_outputs = {}\n",
        "        for lang in ['bodo', 'nepali', 'khasi', 'manipuri', 'mizo', 'assamese']:\n",
        "            dec_targets = targets[lang]\n",
        "            dec_outputs[lang] = self.decoder(dec_targets, enc_outputs, lang, training, masks[lang]['look_ahead_mask'], masks[lang]['dec_padding_mask'])\n",
        "\n",
        "        final_outputs = {}\n",
        "        for lang in ['bodo', 'nepali', 'khasi', 'manipuri', 'mizo', 'assamese']:\n",
        "            final_outputs[lang] = self.final_layers[lang](dec_outputs[lang])\n",
        "\n",
        "        return final_outputs\n",
        "\n",
        "    def encoder(self, inputs, lang, training, enc_padding_mask):\n",
        "        x = self.embedding[lang](inputs)\n",
        "        x += self.pos_encoding[lang]\n",
        "        for layer in self.enc_layers[lang]:\n",
        "            x = layer(x, training, enc_padding_mask)\n",
        "        return x\n",
        "\n",
        "    def decoder(self, targets, enc_outputs, lang, training, look_ahead_mask, dec_padding_mask):\n",
        "        x = self.embedding[lang](targets)\n",
        "        x += self.pos_encoding[lang]\n",
        "        for layer in self.dec_layers[lang]:\n",
        "            x = layer(x, enc_outputs[lang], training, look_ahead_mask, dec_padding_mask)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "68eEcgvRMTr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class MultiTransformer(tf.keras.Model):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size_english, target_vocab_sizes, pe_input, pe_target, rate=0.1):\n",
        "        super(MultiTransformer, self).__init__()\n",
        "\n",
        "        # Embedding for English (source language) and target languages\n",
        "        self.embedding_english = tf.keras.layers.Embedding(input_vocab_size_english, d_model)\n",
        "        self.embedding_targets = {\n",
        "            'assamese': tf.keras.layers.Embedding(target_vocab_sizes['assamese'], d_model),\n",
        "            'bodo': tf.keras.layers.Embedding(target_vocab_sizes['bodo'], d_model),\n",
        "            'khasi': tf.keras.layers.Embedding(target_vocab_sizes['khasi'], d_model),\n",
        "            'manipuri': tf.keras.layers.Embedding(target_vocab_sizes['manipuri'], d_model),\n",
        "            'mizo': tf.keras.layers.Embedding(target_vocab_sizes['mizo'], d_model),\n",
        "            'nepali': tf.keras.layers.Embedding(target_vocab_sizes['nepali'], d_model)\n",
        "        }\n",
        "\n",
        "        # Positional Encodings for English (source language) and target languages\n",
        "        self.pos_encoding_english = positional_encoding(pe_input, d_model)\n",
        "        self.pos_encoding_targets = {\n",
        "            'assamese': positional_encoding(pe_target, d_model),\n",
        "            'bodo': positional_encoding(pe_target, d_model),\n",
        "            'khasi': positional_encoding(pe_target, d_model),\n",
        "            'manipuri': positional_encoding(pe_target, d_model),\n",
        "            'mizo': positional_encoding(pe_target, d_model),\n",
        "            'nepali': positional_encoding(pe_target, d_model)\n",
        "        }\n",
        "\n",
        "        # Shared Encoder\n",
        "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size_english, pe_input, rate)\n",
        "\n",
        "        # Language-specific Decoders\n",
        "        self.decoders = {\n",
        "            'assamese': DecoderAssamese(num_layers, d_model, num_heads, dff, target_vocab_sizes['assamese'], pe_target, rate),\n",
        "            'bodo': DecoderBodo(num_layers, d_model, num_heads, dff, target_vocab_sizes['bodo'], pe_target, rate),\n",
        "            'khasi': DecoderKhasi(num_layers, d_model, num_heads, dff, target_vocab_sizes['khasi'], pe_target, rate),\n",
        "            'manipuri': DecoderManipuri(num_layers, d_model, num_heads, dff, target_vocab_sizes['manipuri'], pe_target, rate),\n",
        "            'mizo': DecoderMizo(num_layers, d_model, num_heads, dff, target_vocab_sizes['mizo'], pe_target, rate),\n",
        "            'nepali': DecoderNepali(num_layers, d_model, num_heads, dff, target_vocab_sizes['nepali'], pe_target, rate)\n",
        "        }\n",
        "\n",
        "        # Final Dense Layers\n",
        "        self.final_layers = {\n",
        "            'assamese': tf.keras.layers.Dense(target_vocab_sizes['assamese']),\n",
        "            'bodo': tf.keras.layers.Dense(target_vocab_sizes['bodo']),\n",
        "            'khasi': tf.keras.layers.Dense(target_vocab_sizes['khasi']),\n",
        "            'manipuri': tf.keras.layers.Dense(target_vocab_sizes['manipuri']),\n",
        "            'mizo': tf.keras.layers.Dense(target_vocab_sizes['mizo']),\n",
        "            'nepali': tf.keras.layers.Dense(target_vocab_sizes['nepali'])\n",
        "        }\n",
        "\n",
        "    def call(self, inputs, targets, training, masks):\n",
        "        enc_inputs = inputs['english']\n",
        "        enc_output = self.encoder(enc_inputs, training, masks['english']['enc_padding_mask'])\n",
        "\n",
        "        dec_outputs = {}\n",
        "        for lang in ['assamese', 'bodo', 'khasi', 'manipuri', 'mizo', 'nepali']:\n",
        "            dec_targets = targets[lang]\n",
        "            dec_outputs[lang] = self.decoders[lang](dec_targets, enc_output, training, masks[lang]['look_ahead_mask'], masks[lang]['dec_padding_mask'])\n",
        "\n",
        "        final_outputs = {}\n",
        "        for lang in ['assamese', 'bodo', 'khasi', 'manipuri', 'mizo', 'nepali']:\n",
        "            final_outputs[lang] = self.final_layers[lang](dec_outputs[lang])\n",
        "\n",
        "        return final_outputs\n",
        "\n",
        "    def encoder(self, inputs, training, enc_padding_mask):\n",
        "        x = self.embedding_english(inputs)\n",
        "        x += self.pos_encoding_english\n",
        "        return self.encoder.call(x, training, enc_padding_mask)\n",
        "\n",
        "    def decoder(self, targets, enc_outputs, lang, training, look_ahead_mask, dec_padding_mask):\n",
        "        x = self.embedding_targets[lang](targets)\n",
        "        x += self.pos_encoding_targets[lang]\n",
        "        return self.decoders[lang].call(x, enc_outputs, training, look_ahead_mask, dec_padding_mask)\n"
      ],
      "metadata": {
        "id": "HF3e3ywQMZgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers = 8\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "dropout_rate = 0.1\n",
        "EPOCHS = 1"
      ],
      "metadata": {
        "id": "RjI1TjAeMbJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(tf.cast(step, tf.float32))\n",
        "        arg2 = tf.cast(step, tf.float32) * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "metadata": {
        "id": "WtO-lNI8McnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, BitsAndBytesConfig\n",
        "from IndicTransTokenizer import IndicProcessor, IndicTransTokenizer\n",
        "\n",
        "BATCH_SIZE = 4\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "quantization = None"
      ],
      "metadata": {
        "id": "fYczM2U6G1Zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_model_and_tokenizer(ckpt_dir, direction, quantization):\n",
        "    if quantization == \"4-bit\":\n",
        "        qconfig = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_use_double_quant=True,\n",
        "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "        )\n",
        "    elif quantization == \"8-bit\":\n",
        "        qconfig = BitsAndBytesConfig(\n",
        "            load_in_8bit=True,\n",
        "            bnb_8bit_use_double_quant=True,\n",
        "            bnb_8bit_compute_dtype=torch.bfloat16,\n",
        "        )\n",
        "    else:\n",
        "        qconfig = None\n",
        "\n",
        "    tokenizer = IndicTransTokenizer(direction=direction)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "        ckpt_dir,\n",
        "        trust_remote_code=True,\n",
        "        low_cpu_mem_usage=True,\n",
        "        quantization_config=qconfig,\n",
        "    )\n",
        "\n",
        "    if qconfig == None:\n",
        "        model = model.to(DEVICE)\n",
        "        if DEVICE == \"cuda\":\n",
        "            model.half()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    return tokenizer, model\n",
        "\n",
        "\n",
        "def batch_translate(input_sentences, src_lang, tgt_lang, model, tokenizer, ip):\n",
        "    translations = []\n",
        "    for i in range(0, len(input_sentences), BATCH_SIZE):\n",
        "        batch = input_sentences[i : i + BATCH_SIZE]\n",
        "\n",
        "        # Preprocess the batch and extract entity mappings\n",
        "        batch = ip.preprocess_batch(batch, src_lang=src_lang, tgt_lang=tgt_lang)\n",
        "\n",
        "        # Tokenize the batch and generate input encodings\n",
        "        inputs = tokenizer(\n",
        "            batch,\n",
        "            src=True,\n",
        "            truncation=True,\n",
        "            padding=\"longest\",\n",
        "            return_tensors=\"pt\",\n",
        "            return_attention_mask=True,\n",
        "        ).to(DEVICE)\n",
        "\n",
        "        # Generate translations using the model\n",
        "        with torch.no_grad():\n",
        "            generated_tokens = model.generate(\n",
        "                **inputs,\n",
        "                use_cache=True,\n",
        "                min_length=0,\n",
        "                max_length=256,\n",
        "                num_beams=5,\n",
        "                num_return_sequences=1,\n",
        "            )\n",
        "\n",
        "        # Decode the generated tokens into text\n",
        "        generated_tokens = tokenizer.batch_decode(generated_tokens.detach().cpu().tolist(), src=False)\n",
        "\n",
        "        # Postprocess the translations, including entity replacement\n",
        "        translations += ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n",
        "\n",
        "        del inputs\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return translations"
      ],
      "metadata": {
        "id": "xj1WCNjuHG-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(tf.cast(step, tf.float32))\n",
        "        arg2 = tf.cast(step, tf.float32) * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "metadata": {
        "id": "S7rLCNA6MsvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the custom learning rate schedule\n",
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = tf.cast(d_model, tf.float32)\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(tf.cast(step, tf.float32))\n",
        "        arg2 = tf.cast(step, tf.float32) * (self.warmup_steps ** -1.5)\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "metadata": {
        "id": "UO7p7xZGMpVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "# Create an optimizer with the custom learning rate\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n"
      ],
      "metadata": {
        "id": "TlUXDaITMmoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "# Create custom learning rate schedules for all language pairs\n",
        "learning_rate_schedule_bodo = CustomSchedule(d_model)\n",
        "learning_rate_schedule_nepali = CustomSchedule(d_model)\n",
        "learning_rate_schedule_khasi = CustomSchedule(d_model)\n",
        "learning_rate_schedule_manipuri = CustomSchedule(d_model)\n",
        "learning_rate_schedule_mizo = CustomSchedule(d_model)\n",
        "learning_rate_schedule_assamese = CustomSchedule(d_model)\n",
        "\n",
        "# Define a function to plot all learning rate schedules on a single graph\n",
        "def plot_all_learning_rate_schedules(schedules, labels, num_steps=40000):\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    for schedule, label in zip(schedules, labels):\n",
        "        plt.plot(tf.range(num_steps, dtype=tf.float32), schedule(tf.range(num_steps, dtype=tf.float32)), label=label)\n",
        "\n",
        "    plt.title(\"Learning Rate Schedules for All Languages\")\n",
        "    plt.xlabel(\"Train Step\")\n",
        "    plt.ylabel(\"Learning Rate\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Create a list of schedules and labels\n",
        "schedules = [\n",
        "    learning_rate_schedule_bodo,\n",
        "    learning_rate_schedule_nepali,\n",
        "    learning_rate_schedule_khasi,\n",
        "    learning_rate_schedule_manipuri,\n",
        "    learning_rate_schedule_mizo,\n",
        "    learning_rate_schedule_assamese\n",
        "]\n",
        "\n",
        "labels = [\n",
        "    \"Bodo\",\n",
        "    \"Nepali\",\n",
        "    \"Khasi\",\n",
        "    \"Manipuri\",\n",
        "    \"Mizo\",\n",
        "    \"Assamese\"\n",
        "]\n",
        "\n",
        "# Plot all learning rate schedules on a single graph\n",
        "plot_all_learning_rate_schedules(schedules, labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "W2So8G5gMjaI",
        "outputId": "6a85a4e3-f1de-40b1-e8b1-40b13b3ef325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
        "\n",
        "\n",
        "def accuracy_function(real, pred):\n",
        "    accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
        "\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    accuracies = tf.math.logical_and(mask, accuracies)\n",
        "\n",
        "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
        "    mask = tf.cast(mask, dtype=tf.float32)\n",
        "    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
      ],
      "metadata": {
        "id": "q0dEPlg8Mvmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')"
      ],
      "metadata": {
        "id": "iFALsAkSMyFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the MultiTransformer class with separate parameters for each decoder\n",
        "class MultiTransformer(tf.keras.Model):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, encoder_vocab_size,\n",
        "                 decoder_bodo_vocab_size, decoder_nepali_vocab_size,\n",
        "                 decoder_khasi_vocab_size, decoder_manipuri_vocab_size,\n",
        "                 decoder_mizo_vocab_size, decoder_assamese_vocab_size,\n",
        "                 pe_input, pe_target, rate):\n",
        "        super(MultiTransformer, self).__init__()\n",
        "        # Initialize encoder and decoders\n",
        "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, encoder_vocab_size, pe_input, rate)\n",
        "        self.decoder_bodo = Decoder(num_layers, d_model, num_heads, dff, decoder_bodo_vocab_size, pe_target, rate)\n",
        "        self.decoder_nepali = Decoder(num_layers, d_model, num_heads, dff, decoder_nepali_vocab_size, pe_target, rate)\n",
        "        self.decoder_khasi = Decoder(num_layers, d_model, num_heads, dff, decoder_khasi_vocab_size, pe_target, rate)\n",
        "        self.decoder_manipuri = Decoder(num_layers, d_model, num_heads, dff, decoder_manipuri_vocab_size, pe_target, rate)\n",
        "        self.decoder_mizo = Decoder(num_layers, d_model, num_heads, dff, decoder_mizo_vocab_size, pe_target, rate)\n",
        "        self.decoder_assamese = Decoder(num_layers, d_model, num_heads, dff, decoder_assamese_vocab_size, pe_target, rate)\n",
        "\n",
        "    def call(self, inputs, targets):\n",
        "        # Process the inputs through the encoder and each decoder\n",
        "        encoder_output = self.encoder(inputs)\n",
        "        decoder_bodo_output = self.decoder_bodo(targets['bodo'], encoder_output)\n",
        "        decoder_nepali_output = self.decoder_nepali(targets['nepali'], encoder_output)\n",
        "        decoder_khasi_output = self.decoder_khasi(targets['khasi'], encoder_output)\n",
        "        decoder_manipuri_output = self.decoder_manipuri(targets['manipuri'], encoder_output)\n",
        "        decoder_mizo_output = self.decoder_mizo(targets['mizo'], encoder_output)\n",
        "        decoder_assamese_output = self.decoder_assamese(targets['assamese'], encoder_output)\n",
        "\n",
        "        return decoder_bodo_output, decoder_nepali_output, decoder_khasi_output, decoder_manipuri_output, decoder_mizo_output, decoder_assamese_output"
      ],
      "metadata": {
        "id": "Sy9fM3ivM0Eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_masks(inp, tar):\n",
        "    enc_padding_mask = create_padding_mask(inp)\n",
        "    dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "    dec_target_padding_mask = create_padding_mask(tar)\n",
        "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "    return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "metadata": {
        "id": "jP27TavrM1_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n"
      ],
      "metadata": {
        "id": "SJoAxVghM3Tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the train_step function\n",
        "@tf.function\n",
        "def train_step(inp_bodo, inp_nepali, tar_bodo, tar_nepali, mask_bodo=None, mask_nepali=None):\n",
        "    # ... (rest of the function remains the same)\n",
        "\n",
        "    # Define masks for language pair Bodo\n",
        "    tar_inp_bodo = tar_bodo[:, :-1]\n",
        "    tar_real_bodo = tar_bodo[:, 1:]\n",
        "    enc_padding_mask_bodo, combined_mask_bodo, dec_padding_mask_bodo = create_masks(inp_bodo, tar_inp_bodo)\n",
        "\n",
        "    # Define masks for language pair Nepali\n",
        "    if tar_nepali is not None:\n",
        "        tar_inp_nepali = tar_nepali[:, :-1]\n",
        "        tar_real_nepali = tar_nepali[:, 1:]\n",
        "        enc_padding_mask_nepali, combined_mask_nepali, dec_padding_mask_nepali = create_masks(inp_nepali, tar_inp_nepali)\n",
        "\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        # Get predictions for language pair Bodo\n",
        "        predictions_bodo, _, _, _ = multi_transformer(\n",
        "            inp_bodo, inp_nepali, tar_inp_bodo, tar_inp_nepali,\n",
        "            True, enc_padding_mask_bodo, combined_mask_bodo, dec_padding_mask_bodo,\n",
        "            enc_padding_mask_nepali, combined_mask_nepali, dec_padding_mask_nepali\n",
        "        )\n",
        "\n",
        "        # Calculate loss for language pair Bodo\n",
        "        loss_bodo = loss_function(tar_real_bodo, predictions_bodo)\n",
        "\n",
        "        # Calculate loss for language pair Nepali if tar_nepali is not None\n",
        "        if tar_nepali is not None:\n",
        "            predictions_nepali, _, _, _ = multi_transformer(\n",
        "                inp_bodo, inp_nepali, tar_inp_bodo, tar_inp_nepali,\n",
        "                True, enc_padding_mask_bodo, combined_mask_bodo, dec_padding_mask_bodo,\n",
        "                enc_padding_mask_nepali, combined_mask_nepali, dec_padding_mask_nepali\n",
        "            )\n",
        "            loss_nepali = loss_function(tar_real_nepali, predictions_nepali)\n",
        "            total_loss = loss_bodo + loss_nepali\n",
        "        else:\n",
        "            total_loss = loss_bodo\n",
        "\n",
        "    # Calculate gradients and apply them using the optimizer\n",
        "    gradients = tape.gradient(total_loss, multi_transformer.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, multi_transformer.trainable_variables))\n",
        "\n",
        "    # Update metrics\n",
        "    train_loss(total_loss)\n",
        "    train_accuracy(accuracy_function(tar_real_bodo, predictions_bodo))\n",
        "\n",
        "# Define train_loss and train_accuracy\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')\n",
        "\n"
      ],
      "metadata": {
        "id": "YSHkLfwHM4xX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### English to Indic Example\n"
      ],
      "metadata": {
        "id": "erNCuZTEMt49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "en_sents = [\n",
        "    \"He was a king too.\",\n",
        "    \"He slept the whole night.\",\n",
        "    \"They have failed.\",\n",
        "    \"Open a new browser.\",\n",
        "    \"he wrote well in the examination \",\n",
        "    \"You must specify a file name\",\n",
        "]\n"
      ],
      "metadata": {
        "id": "rTMNFb2Atrat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "en_indic_ckpt_dir = \"ai4bharat/indictrans2-en-indic-1B\"  # ai4bharat/indictrans2-en-indic-dist-200M\n",
        "en_indic_tokenizer, en_indic_model = initialize_model_and_tokenizer(en_indic_ckpt_dir, \"en-indic\", quantization)\n",
        "\n",
        "ip = IndicProcessor(inference=True)\n",
        "\n",
        "\n",
        "src_lang, tgt_lang = \"eng_Latn\", \"asm_Beng\"\n",
        "asm_translations = batch_translate(en_sents, src_lang, tgt_lang, en_indic_model, en_indic_tokenizer, ip)\n",
        "\n",
        "print(f\"\\n{src_lang} - {tgt_lang}\")\n",
        "print(\"------------------------------------------------\")\n",
        "\n",
        "for input_sentence, translation in zip(en_sents, asm_translations):\n",
        "    print(f\"{src_lang}: {input_sentence}\")\n",
        "    print(f\"{tgt_lang}: {translation}\")\n",
        "    asm_translations = {translation}\n",
        "    # Print the output list (for demonstration)\n",
        "    print(\"------------------------------------------------\")\n",
        "\n",
        "# flush the models to free the GPU memory\n",
        "del en_indic_tokenizer, en_indic_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZM3whbc3sVA",
        "outputId": "e98e2c89-55dd-4404-901b-86fc46638000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "eng_Latn - asm_Beng\n",
            "------------------------------------------------\n",
            "eng_Latn: He was a king too.\n",
            "asm_Beng: তেওঁ এজন ৰজাও আছিল।\n",
            "------------------------------------------------\n",
            "eng_Latn: He slept the whole night.\n",
            "asm_Beng: গোটেই ৰাতি তেওঁ শুই আছিল।\n",
            "------------------------------------------------\n",
            "eng_Latn: They have failed.\n",
            "asm_Beng: তেওঁলোক বিফল হৈছিল।\n",
            "------------------------------------------------\n",
            "eng_Latn: Open a new browser.\n",
            "asm_Beng: এটা নতুন ব্ৰাউজাৰ খোলক।\n",
            "------------------------------------------------\n",
            "eng_Latn: he wrote well in the examination \n",
            "asm_Beng: তেওঁ পৰীক্ষাত ভালদৰে লিখিছিল\n",
            "------------------------------------------------\n",
            "eng_Latn: You must specify a file name\n",
            "asm_Beng: আপুনি এটা ফাইলৰ নাম উল্লেখ কৰিব লাগিব\n",
            "------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "en_indic_ckpt_dir = \"ai4bharat/indictrans2-en-indic-1B\"  # ai4bharat/indictrans2-en-indic-dist-200M\n",
        "en_indic_tokenizer, en_indic_model = initialize_model_and_tokenizer(en_indic_ckpt_dir, \"en-indic\", quantization)\n",
        "\n",
        "ip = IndicProcessor(inference=True)\n",
        "\n",
        "\n",
        "src_lang, tgt_lang = \"eng_Latn\", \"brx_Deva\"\n",
        "brx_translations = batch_translate(en_sents, src_lang, tgt_lang, en_indic_model, en_indic_tokenizer, ip)\n",
        "\n",
        "print(f\"\\n{src_lang} - {tgt_lang}\")\n",
        "print(\"------------------------------------------------\")\n",
        "\n",
        "for input_sentence, translation in zip(en_sents, brx_translations):\n",
        "    print(f\"{src_lang}: {input_sentence}\")\n",
        "    print(f\"{tgt_lang}: {translation}\")\n",
        "    brx_translations = {translation}\n",
        "    # Print the output list (for demonstration)\n",
        "    print(\"------------------------------------------------\")\n",
        "\n",
        "# flush the models to free the GPU memory\n",
        "del en_indic_tokenizer, en_indic_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIYbhr2b5jqJ",
        "outputId": "26a6b156-7863-4629-9f8f-ebd8b8bccda5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "eng_Latn - brx_Deva\n",
            "------------------------------------------------\n",
            "eng_Latn: He was a king too.\n",
            "brx_Deva: बियो सासे राजाबोमोन।\n",
            "------------------------------------------------\n",
            "eng_Latn: He slept the whole night.\n",
            "brx_Deva: बियो गासै हरावनो उन्दुदोंमोन।\n",
            "------------------------------------------------\n",
            "eng_Latn: They have failed.\n",
            "brx_Deva: बिसोर फेलें जाबाय।\n",
            "------------------------------------------------\n",
            "eng_Latn: Open a new browser.\n",
            "brx_Deva: मोनसे गोदान ब्राउजार खेव।\n",
            "------------------------------------------------\n",
            "eng_Latn: he wrote well in the examination \n",
            "brx_Deva: बियो आनजादयाव मोजाङै लिरदोंमोन।\n",
            "------------------------------------------------\n",
            "eng_Latn: You must specify a file name\n",
            "brx_Deva: नों मोनसे फाइलनि मुंखौ थि खालामथारनांगोन।\n",
            "------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "en_indic_ckpt_dir = \"ai4bharat/indictrans2-en-indic-1B\"  # ai4bharat/indictrans2-en-indic-dist-200M\n",
        "en_indic_tokenizer, en_indic_model = initialize_model_and_tokenizer(en_indic_ckpt_dir, \"en-indic\", quantization)\n",
        "\n",
        "ip = IndicProcessor(inference=True)\n",
        "\n",
        "\n",
        "src_lang, tgt_lang = \"eng_Latn\", \"npi_Deva\"\n",
        "npi_translations = batch_translate(en_sents, src_lang, tgt_lang, en_indic_model, en_indic_tokenizer, ip)\n",
        "\n",
        "print(f\"\\n{src_lang} - {tgt_lang}\")\n",
        "print(\"------------------------------------------------\")\n",
        "for input_sentence, translation in zip(en_sents, npi_translations):\n",
        "    print(f\"{src_lang}: {input_sentence}\")\n",
        "    print(f\"{tgt_lang}: {translation}\")\n",
        "    npi_translations = {translation}\n",
        "    # Print the output list (for demonstration)\n",
        "    print(\"------------------------------------------------\")\n",
        "\n",
        "# flush the models to free the GPU memory\n",
        "del en_indic_tokenizer, en_indic_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UArJGLXGt3_V",
        "outputId": "dc17dd02-6cbe-486b-c757-c865d3145962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "eng_Latn - npi_Deva\n",
            "------------------------------------------------\n",
            "eng_Latn: He was a king too.\n",
            "npi_Deva: उनी पनि राजा थिए।\n",
            "------------------------------------------------\n",
            "eng_Latn: He slept the whole night.\n",
            "npi_Deva: उनी रातभरि सुतिरहेका थिए।\n",
            "------------------------------------------------\n",
            "eng_Latn: They have failed.\n",
            "npi_Deva: तिनीहरू असफल भएका छन्।\n",
            "------------------------------------------------\n",
            "eng_Latn: Open a new browser.\n",
            "npi_Deva: नयाँ ब्राउजर खोल्नुहोस्।\n",
            "------------------------------------------------\n",
            "eng_Latn: he wrote well in the examination \n",
            "npi_Deva: उनले परीक्षामा राम्रो लेखे।\n",
            "------------------------------------------------\n",
            "eng_Latn: You must specify a file name\n",
            "npi_Deva: तपाईँले फाइलको नाम निर्दिष्ट गर्नुपर्छ\n",
            "------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming ekha is imported and has the khasi_translate function\n",
        "import ekha\n",
        "\n",
        "\n",
        "# Function to generate list of formatted translations\n",
        "def khasi_output(eng_sents):\n",
        "    output = []\n",
        "    for sentence in eng_sents:\n",
        "        khasi_translation = ekha.khasi_translate(sentence)  # Use ekha's translation function\n",
        "        output.append(f\"eng_Latn: {sentence}\")\n",
        "        output.append(f\"kha_Latn: {khasi_translation}\")\n",
        "        output.append(\"\")  # Add a blank line for separation\n",
        "    return output\n",
        "\n",
        "# Get the output list\n",
        "output_list = khasi_output(en_sents)\n",
        "\n",
        "# Print the output list (for demonstration)\n",
        "for line in output_list:\n",
        "    print(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRcUQjn_1yez",
        "outputId": "c4090915-4317-48f9-d07f-b5940e34486f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eng_Latn: He was a king too.\n",
            "kha_Latn: u syiem u la pynlut haduh snem\n",
            "\n",
            "eng_Latn: He slept the whole night.\n",
            "kha_Latn: u thiah mynmiet u thiah shimiet\n",
            "\n",
            "eng_Latn: They have failed.\n",
            "kha_Latn: hato kim don umjer nangno ki ing kim don jingbam\n",
            "\n",
            "eng_Latn: Open a new browser.\n",
            "kha_Latn: plie ki jingduwai bathymmai\n",
            "\n",
            "eng_Latn: he wrote well in the examination \n",
            "kha_Latn: u thoh bha bha ha ka examination\n",
            "\n",
            "eng_Latn: You must specify a file name\n",
            "kha_Latn: ka jingbhabriew ka dei ka maakah ka ingbishar\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "en_indic_ckpt_dir = \"ai4bharat/indictrans2-en-indic-1B\"  # ai4bharat/indictrans2-en-indic-dist-200M\n",
        "en_indic_tokenizer, en_indic_model = initialize_model_and_tokenizer(en_indic_ckpt_dir, \"en-indic\", quantization)\n",
        "\n",
        "ip = IndicProcessor(inference=True)\n",
        "\n",
        "\n",
        "src_lang, tgt_lang = \"eng_Latn\", \"mni_Beng\"\n",
        "mni_translations = batch_translate(en_sents, src_lang, tgt_lang, en_indic_model, en_indic_tokenizer, ip)\n",
        "\n",
        "print(f\"\\n{src_lang} - {tgt_lang}\")\n",
        "print(\"------------------------------------------------\")\n",
        "for input_sentence, translation in zip(en_sents, mni_translations):\n",
        "    print(f\"{src_lang}: {input_sentence}\")\n",
        "    print(f\"{tgt_lang}: {translation}\")\n",
        "    mni_translations = {translation}\n",
        "    # Print the output list (for demonstration)\n",
        "    print(\"------------------------------------------------\")\n",
        "\n",
        "# flush the models to free the GPU memory\n",
        "del en_indic_tokenizer, en_indic_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-Ffb66Q35Rj",
        "outputId": "3b0194e8-9337-40ca-bc7e-eec7cd41f9d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "eng_Latn - mni_Beng\n",
            "------------------------------------------------\n",
            "eng_Latn: He was a king too.\n",
            "mni_Beng: মহাক এপার্থিদকী মায়োক্তা লৈবা এক্তিবিস্ত অমনি।\n",
            "------------------------------------------------\n",
            "eng_Latn: He slept the whole night.\n",
            "mni_Beng: নুমিদাং ফাওবা অসুম অসুম থেঙজিল্লক্লি।\n",
            "------------------------------------------------\n",
            "eng_Latn: They have failed.\n",
            "mni_Beng: অদুবু মখোয়না খঙদবা হায়বসি য়াম্না লাইবক থিবা অমনি।\n",
            "------------------------------------------------\n",
            "eng_Latn: Open a new browser.\n",
            "mni_Beng: অনৌবা পেজ অমা হাপচিনবা\n",
            "------------------------------------------------\n",
            "eng_Latn: he wrote well in the examination \n",
            "mni_Beng: মহাক্না চাংয়েং অদুদা নীংথিনা ইখি।\n",
            "------------------------------------------------\n",
            "eng_Latn: You must specify a file name\n",
            "mni_Beng: অদোম্না ফাইল অমগী মমিং পীবা তাই।\n",
            "------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming elus is imported and has the mizo_translate function\n",
        "import elus\n",
        "\n",
        "\n",
        "# Function to generate list of formatted translations for Mizo\n",
        "def mizo_output(eng_sents):\n",
        "    output = []\n",
        "    for sentence in eng_sents:\n",
        "        mizo_translation = elus.mizo_translate(sentence)  # Use elus's translation function\n",
        "        output.append(f\"eng_Latn: {sentence}\")\n",
        "        output.append(f\"mizo_Latn: {mizo_translation}\")\n",
        "        output.append(\"\")  # Add a blank line for separation\n",
        "    return output\n",
        "\n",
        "# Get the output list\n",
        "output_list_mizo = mizo_output(en_sents)\n",
        "\n",
        "# Print the output list (for demonstration)\n",
        "for line in output_list_mizo:\n",
        "    print(line)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4WdhuIX2-ug",
        "outputId": "128c0617-597f-4589-e917-bb9a04b8bcc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eng_Latn: He was a king too.\n",
            "mizo_Latn: lal a ni\n",
            "\n",
            "eng_Latn: He slept the whole night.\n",
            "mizo_Latn: zan khat chu a mu\n",
            "\n",
            "eng_Latn: They have failed.\n",
            "mizo_Latn: an nei lo\n",
            "\n",
            "eng_Latn: Open a new browser.\n",
            "mizo_Latn: sum thar thawk thar\n",
            "\n",
            "eng_Latn: he wrote well in the examination \n",
            "mizo_Latn: a tha khawp mai\n",
            "\n",
            "eng_Latn: You must specify a file name\n",
            "mizo_Latn: lalber chuan ani chu tihhlum a ni dwn tih tu nge a tiam a\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluation Metrics**"
      ],
      "metadata": {
        "id": "OM_1pbPtMpV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyter3\n",
        "!pip install sacrebleu\n",
        "!pip install rouge_score\n",
        "import nltk\n",
        "nltk.download('punkt')  # Download the Punkt tokenizer\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brdN7JEo8r0Y",
        "outputId": "7625a253-cf51-4742-ba99-12be1d3f9e97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyter3\n",
            "  Downloading pyter3-0.3-py3-none-any.whl.metadata (3.2 kB)\n",
            "Downloading pyter3-0.3-py3-none-any.whl (4.1 kB)\n",
            "Installing collected packages: pyter3\n",
            "Successfully installed pyter3-0.3\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.4.2-py3-none-any.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2024.5.15)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.26.4)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n",
            "Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-2.10.1 sacrebleu-2.4.2\n",
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.4)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=bc5415847a0edb68b3ac0737ed73b846a343084387102fb4420fbee4a3952e3c\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu, SmoothingFunction\n",
        "\n",
        "# Load actual translations from actual.csv\n",
        "with open('/content/drive/MyDrive//multilingual/eng_to_indic/as/actual_assamese.csv', 'r') as file:\n",
        "    actual_reader = csv.reader(file)\n",
        "    actual_translations = [row[0].split() for row in actual_reader]\n",
        "\n",
        "# Load predicted translations from predicted.csv\n",
        "with open('/content/drive/MyDrive//multilingual/eng_to_indic/as/prediction_assamese.csv', 'r') as file:\n",
        "    predicted_reader = csv.reader(file)\n",
        "    predicted_translations = [row[0].split() for row in predicted_reader]\n",
        "\n",
        "# Define a smoothing function for BLEU score calculation\n",
        "smoothie = SmoothingFunction().method1\n",
        "\n",
        "# Compute BLEU score for corpus level with smoothing\n",
        "corpus_score = corpus_bleu(actual_translations, predicted_translations, smoothing_function=smoothie)\n",
        "\n",
        "# Compute BLEU score for sentence level with smoothing\n",
        "sentence_scores = [sentence_bleu([actual], predicted, smoothing_function=smoothie) for actual, predicted in zip(actual_translations, predicted_translations)]\n",
        "\n",
        "# Calculate average sentence level BLEU score\n",
        "avg_sentence_score = sum(sentence_scores) / len(sentence_scores)\n",
        "\n",
        "# Print the scores\n",
        "# print(\"Corpus BLEU score:\", corpus_score)\n",
        "print(\"Assamese BLEU score:\", avg_sentence_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJR_xWn99DP_",
        "outputId": "25114833-dd99-4ef1-f648-20ecc35e16bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assamese BLEU score: 0.2795884109211922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import sacrebleu\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "# Load reference and prediction CSV files\n",
        "reference_file = '/content/drive/MyDrive//multilingual/eng_to_indic/as/actual_assamese.csv'\n",
        "prediction_file = '/content/drive/MyDrive//multilingual/eng_to_indic/as/prediction_assamese.csv'\n",
        "\n",
        "reference_df = pd.read_csv(reference_file)\n",
        "prediction_df = pd.read_csv(prediction_file)\n",
        "\n",
        "\n",
        "references = reference_df['ASSAMESE'].tolist()\n",
        "predictions = prediction_df['ASSAMESE'].tolist()\n",
        "\n",
        "# Calculate SacreBLEU score\n",
        "sacrebleu_score = sacrebleu.corpus_bleu(predictions, [references]).score\n",
        "print(f\"Assamese SacreBLEU Score: {sacrebleu_score/100}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMCOo5d29Lhh",
        "outputId": "16271a00-e595-4e82-e26f-69314cab8291"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assamese SacreBLEU Score: 0.240036184434208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import nltk\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "# File paths\n",
        "reference_file = '/content/drive/MyDrive//multilingual/eng_to_indic/as/actual_assamese.csv'  # Path to the CSV file containing reference Nepali translations\n",
        "prediction_file = '/content/drive/MyDrive//multilingual/eng_to_indic/as/prediction_assamese.csv'  # Path to the CSV file containing model's predicted Nepali translations\n",
        "\n",
        "# Initialize lists to hold reference and predicted sentences\n",
        "references = []\n",
        "predictions = []\n",
        "\n",
        "# Read reference translations from CSV file\n",
        "with open(reference_file, 'r') as ref_csv:\n",
        "    reader = csv.reader(ref_csv)\n",
        "    next(reader)  # Skip header\n",
        "    for row in reader:\n",
        "        # Tokenize the reference sentence\n",
        "        references.append(word_tokenize(row[0]))  # Assuming the reference text is in the first column\n",
        "\n",
        "# Read model predictions from CSV file\n",
        "with open(prediction_file, 'r') as pred_csv:\n",
        "    reader = csv.reader(pred_csv)\n",
        "    next(reader)  # Skip header\n",
        "    for row in reader:\n",
        "        # Tokenize the prediction sentence\n",
        "        predictions.append(word_tokenize(row[0]))  # Assuming the prediction text is in the first column\n",
        "\n",
        "# Ensure references and predictions have the same length\n",
        "assert len(references) == len(predictions), \"References and predictions must have the same length\"\n",
        "\n",
        "# Calculate the METEOR score for each pair of reference and prediction\n",
        "total_meteor_score = 0.0\n",
        "num_sentences = len(references)\n",
        "\n",
        "for ref, pred in zip(references, predictions):\n",
        "    score = meteor_score([ref], pred)\n",
        "    total_meteor_score += score\n",
        "\n",
        "# Calculate the average METEOR score\n",
        "avg_meteor_score = total_meteor_score / num_sentences\n",
        "\n",
        "print(f\"Assamese METEOR Score: {avg_meteor_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WJklnl89M_h",
        "outputId": "f41c3f55-ee44-4c15-e5f8-aa3b62276359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assamese METEOR Score: 0.4123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "# Initialize a ROUGE scorer\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "# File paths\n",
        "reference_file = '/content/drive/MyDrive//multilingual/eng_to_indic/as/actual_assamese.csv'  # Path to the CSV file containing reference Nepali translations\n",
        "prediction_file = '/content/drive/MyDrive//multilingual/eng_to_indic/as/prediction_assamese.csv'  # Path to the CSV file containing model's predicted Nepali translations\n",
        "\n",
        "# Initialize lists to hold ROUGE scores\n",
        "rouge1_scores = []\n",
        "rouge2_scores = []\n",
        "rougeL_scores = []\n",
        "\n",
        "# Read reference translations from CSV file\n",
        "with open(reference_file, 'r') as ref_csv:\n",
        "    reader = csv.reader(ref_csv)\n",
        "    next(reader)  # Skip header\n",
        "    references = [row[0] for row in reader]\n",
        "\n",
        "with open(prediction_file, 'r') as pred_csv:\n",
        "    reader = csv.reader(pred_csv)\n",
        "    next(reader)  # Skip header\n",
        "    predictions = [row[0] for row in reader]\n",
        "\n",
        "# Calculate the ROUGE scores for each pair of reference and prediction\n",
        "for ref, pred in zip(references, predictions):\n",
        "    scores = scorer.score(ref, pred)\n",
        "    rouge1_scores.append(scores['rouge1'].fmeasure)\n",
        "    rouge2_scores.append(scores['rouge2'].fmeasure)\n",
        "    rougeL_scores.append(scores['rougeL'].fmeasure)\n",
        "\n",
        "# Calculate average ROUGE scores\n",
        "avg_rouge1 = sum(rouge1_scores) / len(rouge1_scores)\n",
        "avg_rouge2 = sum(rouge2_scores) / len(rouge2_scores)\n",
        "avg_rougeL = sum(rougeL_scores) / len(rougeL_scores)\n",
        "\n",
        "\n",
        "print(f\"Assamese ROUGE Score: {avg_rouge1:.4f}\")\n",
        "#print(f\"Assamese ROUGE Score: {avg_rouge2:.4f}\")\n",
        "#print(f\"ROUGE-L Score: {avg_rougeL:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gH3sSmbM9PJy",
        "outputId": "c1eb3869-2b1f-4157-acd8-f807f68a7692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assamese ROUGE Score: 0.1467\n",
            "Assamese ROUGE Score: 0.0400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyter\n",
        "reference_as_file = '/content/drive/MyDrive//multilingual/eng_to_indic/as/actual_assamese.csv'\n",
        "hypothesis_as_file = '/content/drive/MyDrive//multilingual/eng_to_indic/as/prediction_assamese.csv'\n",
        "ter_score = pyter.ter(reference_as_file, hypothesis_as_file)\n",
        "print(f\"TER Assamese Score: {ter_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JNdcfXf9UNb",
        "outputId": "c78d6690-4d09-4943-843e-332eb883a0ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TER Assamese Score: 0.10526315789473684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bodo**"
      ],
      "metadata": {
        "id": "bkw8ArOf9VIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu, SmoothingFunction\n",
        "\n",
        "# Load actual translations from actual.csv\n",
        "with open('/content/drive/MyDrive//multilingual/eng_to_indic/brx/actual.csv', 'r') as file:\n",
        "    actual_reader = csv.reader(file)\n",
        "    actual_translations = [row[0].split() for row in actual_reader]\n",
        "\n",
        "# Load predicted translations from predicted.csv\n",
        "with open('/content/drive/MyDrive//multilingual/eng_to_indic/brx/prediction_bodo.csv', 'r') as file:\n",
        "    predicted_reader = csv.reader(file)\n",
        "    predicted_translations = [row[0].split() for row in predicted_reader]\n",
        "\n",
        "# Define a smoothing function for BLEU score calculation\n",
        "smoothie = SmoothingFunction().method1\n",
        "\n",
        "# Compute BLEU score for corpus level with smoothing\n",
        "corpus_score = corpus_bleu(actual_translations, predicted_translations, smoothing_function=smoothie)\n",
        "\n",
        "# Compute BLEU score for sentence level with smoothing\n",
        "sentence_scores = [sentence_bleu([actual], predicted, smoothing_function=smoothie) for actual, predicted in zip(actual_translations, predicted_translations)]\n",
        "\n",
        "# Calculate average sentence level BLEU score\n",
        "avg_sentence_score = sum(sentence_scores) / len(sentence_scores)\n",
        "\n",
        "# Print the scores\n",
        "# print(\"Corpus BLEU score:\", corpus_score)\n",
        "print(\"Bodo BLEU score:\", avg_sentence_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PapzNygx9n6I",
        "outputId": "1980ae13-afbb-4509-a634-540536a96fe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bodo BLEU score: 0.24187137243578544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import sacrebleu\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "# Load reference and prediction CSV files\n",
        "reference_file = '/content/drive/MyDrive//multilingual/eng_to_indic/brx/actual.csv'\n",
        "prediction_file = '/content/drive/MyDrive//multilingual/eng_to_indic/brx/prediction_bodo.csv'\n",
        "\n",
        "reference_df = pd.read_csv(reference_file)\n",
        "prediction_df = pd.read_csv(prediction_file)\n",
        "\n",
        "\n",
        "references = reference_df['BODO'].tolist()\n",
        "predictions = prediction_df['BODO'].tolist()\n",
        "\n",
        "# Calculate SacreBLEU score\n",
        "sacrebleu_score = sacrebleu.corpus_bleu(predictions, [references]).score\n",
        "print(f\" Bodo SacreBLEU Score: {sacrebleu_score/100}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTSKUz3D9nxV",
        "outputId": "5eeceacc-3a2b-4d03-8a34-6bb515ccfcb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Bodo SacreBLEU Score: 0.17077413927287693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "# Initialize a ROUGE scorer\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "# File paths\n",
        "reference_file = '/content/drive/MyDrive//multilingual/eng_to_indic/brx/actual.csv'  # Path to the CSV file containing reference Nepali translations\n",
        "prediction_file = '/content/drive/MyDrive//multilingual/eng_to_indic/brx/prediction_bodo.csv'  # Path to the CSV file containing model's predicted Nepali translations\n",
        "\n",
        "# Initialize lists to hold ROUGE scores\n",
        "rouge1_scores = []\n",
        "rouge2_scores = []\n",
        "rougeL_scores = []\n",
        "\n",
        "# Read reference translations from CSV file\n",
        "with open(reference_file, 'r') as ref_csv:\n",
        "    reader = csv.reader(ref_csv)\n",
        "    next(reader)  # Skip header\n",
        "    references = [row[0] for row in reader]\n",
        "\n",
        "with open(prediction_file, 'r') as pred_csv:\n",
        "    reader = csv.reader(pred_csv)\n",
        "    next(reader)  # Skip header\n",
        "    predictions = [row[0] for row in reader]\n",
        "\n",
        "# Calculate the ROUGE scores for each pair of reference and prediction\n",
        "for ref, pred in zip(references, predictions):\n",
        "    scores = scorer.score(ref, pred)\n",
        "    rouge1_scores.append(scores['rouge1'].fmeasure)\n",
        "    rouge2_scores.append(scores['rouge2'].fmeasure)\n",
        "    rougeL_scores.append(scores['rougeL'].fmeasure)\n",
        "\n",
        "# Calculate average ROUGE scores\n",
        "avg_rouge1 = sum(rouge1_scores) *10/ len(rouge1_scores)\n",
        "avg_rouge2 = sum(rouge2_scores) *10/ len(rouge2_scores)\n",
        "avg_rougeL = sum(rougeL_scores) *10 / len(rougeL_scores)\n",
        "# print(\"\")\n",
        "#print(f\" ROUGE-1 Score: {avg_rouge1:.4f}\")\n",
        "print(f\"Bodo  ROUGE Score: {avg_rouge2:.4f}\")\n",
        "# print(f\" ROUGE-L Score: {avg_rougeL:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QJCih-l9noJ",
        "outputId": "a5e26537-d93f-4714-8e7e-6b1ac31545e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bodo  ROUGE Score: 0.1231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import nltk\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "\n",
        "# File paths\n",
        "reference_file = '/content/drive/MyDrive//multilingual/eng_to_indic/brx/actual.csv'  # Path to the CSV file containing reference Nepali translations\n",
        "prediction_file = '/content/drive/MyDrive//multilingual/eng_to_indic/brx/prediction_bodo.csv'  # Path to the CSV file containing model's predicted Nepali translations\n",
        "\n",
        "# Initialize lists to hold reference and predicted sentences\n",
        "references = []\n",
        "predictions = []\n",
        "\n",
        "# Read reference translations from CSV file\n",
        "with open(reference_file, 'r') as ref_csv:\n",
        "    reader = csv.reader(ref_csv)\n",
        "    next(reader)  # Skip header\n",
        "    for row in reader:\n",
        "        # Tokenize the reference sentence\n",
        "        references.append(word_tokenize(row[0]))  # Assuming the reference text is in the first column\n",
        "\n",
        "# Read model predictions from CSV file\n",
        "with open(prediction_file, 'r') as pred_csv:\n",
        "    reader = csv.reader(pred_csv)\n",
        "    next(reader)  # Skip header\n",
        "    for row in reader:\n",
        "        # Tokenize the prediction sentence\n",
        "        predictions.append(word_tokenize(row[0]))  # Assuming the prediction text is in the first column\n",
        "\n",
        "# Ensure references and predictions have the same length\n",
        "assert len(references) == len(predictions), \"References and predictions must have the same length\"\n",
        "\n",
        "# Calculate the METEOR score for each pair of reference and prediction\n",
        "total_meteor_score = 0.0\n",
        "num_sentences = len(references)\n",
        "\n",
        "for ref, pred in zip(references, predictions):\n",
        "    score = meteor_score([ref], pred)\n",
        "    total_meteor_score += score\n",
        "\n",
        "# Calculate the average METEOR score\n",
        "avg_meteor_score = total_meteor_score / num_sentences\n",
        "\n",
        "print(f\"Bodo METEOR Score: {avg_meteor_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_rDhl0n9neN",
        "outputId": "ec7c6b22-77bd-4081-f965-9d2cfdefa695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bodo METEOR Score: 0.3098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyter\n",
        "reference_brx_file = '/content/drive/MyDrive//multilingual/eng_to_indic/brx/actual_bodo.csv'\n",
        "hypothesis_brx_file = '/content/drive/MyDrive//multilingual/eng_to_indic/brx/prediction_bodo.csv'\n",
        "ter_score = pyter.ter(reference_brx_file, hypothesis_brx_file)\n",
        "print(f\"TER Bodo Score: {ter_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atvOI6Ek9nPZ",
        "outputId": "dcb677c2-1ecd-4e68-9176-e10d48acf073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TER Bodo Score: 0.1095890410958904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Khasi**"
      ],
      "metadata": {
        "id": "FRVENNW290-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu, SmoothingFunction\n",
        "\n",
        "# Load actual translations from actual.csv\n",
        "with open('/content/drive/MyDrive//multilingual/eng_to_indic/kha/actual_khasi.csv', 'r') as file:\n",
        "    actual_reader = csv.reader(file)\n",
        "    actual_translations = [row[0].split() for row in actual_reader]\n",
        "\n",
        "# Load predicted translations from predicted.csv\n",
        "with open('/content/drive/MyDrive//multilingual/eng_to_indic/kha/prediction_khasi.csv', 'r') as file:\n",
        "    predicted_reader = csv.reader(file)\n",
        "    predicted_translations = [row[0].split() for row in predicted_reader]\n",
        "\n",
        "# Define a smoothing function for BLEU score calculation\n",
        "smoothie = SmoothingFunction().method1\n",
        "\n",
        "# Compute BLEU score for corpus level with smoothing\n",
        "corpus_score = corpus_bleu(actual_translations, predicted_translations, smoothing_function=smoothie)\n",
        "\n",
        "# Compute BLEU score for sentence level with smoothing\n",
        "sentence_scores = [sentence_bleu([actual], predicted, smoothing_function=smoothie) for actual, predicted in zip(actual_translations, predicted_translations)]\n",
        "\n",
        "# Calculate average sentence level BLEU score\n",
        "avg_sentence_score = sum(sentence_scores) / len(sentence_scores)\n",
        "\n",
        "# Print the scores\n",
        "# print(\"Corpus BLEU score:\", corpus_score)\n",
        "print(\"Khasi BLEU score:\", avg_sentence_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7aQAwAl95Ay",
        "outputId": "a774731e-2a86-4851-8906-5498c6f3dfe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Khasi BLEU score: 0.10968701661703499\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import sacrebleu\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "# Load reference and prediction CSV files\n",
        "reference_file = '/content/drive/MyDrive//multilingual/eng_to_indic/kha/actual_khasi.csv'\n",
        "prediction_file = '/content/drive/MyDrive//multilingual/eng_to_indic/kha/prediction_khasi.csv'\n",
        "\n",
        "reference_df = pd.read_csv(reference_file)\n",
        "prediction_df = pd.read_csv(prediction_file)\n",
        "\n",
        "\n",
        "references = reference_df['KHASI'].tolist()\n",
        "predictions = prediction_df['KHASI'].tolist()\n",
        "\n",
        "# Calculate SacreBLEU score\n",
        "sacrebleu_score = sacrebleu.corpus_bleu(predictions, [references]).score\n",
        "print(f\"Khasi SacreBLEU Score: {sacrebleu_score/100}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAWV0Nn69450",
        "outputId": "6aac8bd5-91e4-4179-d157-dce0fc9a6d89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Khasi SacreBLEU Score: 0.14372333610745275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "# Initialize a ROUGE scorer\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "\n",
        "# Load actual and prediction data from CSV files\n",
        "reference_file = '/content/drive/MyDrive//multilingual/eng_to_indic/kha/actual_khasi.csv'\n",
        "prediction_file = '/content/drive/MyDrive//multilingual/eng_to_indic/kha/prediction_khasi.csv'\n",
        "\n",
        "# Initialize lists to hold ROUGE scores\n",
        "rouge1_scores = []\n",
        "rouge2_scores = []\n",
        "rougeL_scores = []\n",
        "\n",
        "# Read reference translations from CSV file\n",
        "with open(reference_file, 'r') as ref_csv:\n",
        "    reader = csv.reader(ref_csv)\n",
        "    next(reader)  # Skip header\n",
        "    references = [row[0] for row in reader]\n",
        "\n",
        "with open(prediction_file, 'r') as pred_csv:\n",
        "    reader = csv.reader(pred_csv)\n",
        "    next(reader)  # Skip header\n",
        "    predictions = [row[0] for row in reader]\n",
        "\n",
        "# Calculate the ROUGE scores for each pair of reference and prediction\n",
        "for ref, pred in zip(references, predictions):\n",
        "    scores = scorer.score(ref, pred)\n",
        "    rouge1_scores.append(scores['rouge1'].fmeasure)\n",
        "    rouge2_scores.append(scores['rouge2'].fmeasure)\n",
        "    rougeL_scores.append(scores['rougeL'].fmeasure)\n",
        "\n",
        "# Calculate average ROUGE scores\n",
        "avg_rouge1 = sum(rouge1_scores) / len(rouge1_scores)\n",
        "avg_rouge2 = sum(rouge2_scores) / len(rouge2_scores)\n",
        "avg_rougeL = sum(rougeL_scores) / len(rougeL_scores)\n",
        "\n",
        "\n",
        "# print(f\"ROUGE-1 Score: {avg_rouge1:.4f}\")\n",
        "print(f\"Khasi ROUGE Score: {avg_rouge2:.4f}\")\n",
        "# print(f\"ROUGE-L Score: {avg_rougeL:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJuvLUom94yX",
        "outputId": "d693d980-c0db-4e23-e270-2614e26eeea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Khasi ROUGE Score: 0.1967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import nltk\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "# Load actual and prediction data from CSV files\n",
        "reference_file = '/content/drive/MyDrive//multilingual/eng_to_indic/kha/actual_khasi.csv'\n",
        "prediction_file = '/content/drive/MyDrive//multilingual/eng_to_indic/kha/prediction_khasi.csv'\n",
        "\n",
        "# Initialize lists to hold reference and predicted sentences\n",
        "references = []\n",
        "predictions = []\n",
        "\n",
        "# Read reference translations from CSV file\n",
        "with open(reference_file, 'r') as ref_csv:\n",
        "    reader = csv.reader(ref_csv)\n",
        "    next(reader)  # Skip header\n",
        "    for row in reader:\n",
        "        # Tokenize the reference sentence\n",
        "        references.append(word_tokenize(row[0]))  # Assuming the reference text is in the first column\n",
        "\n",
        "# Read model predictions from CSV file\n",
        "with open(prediction_file, 'r') as pred_csv:\n",
        "    reader = csv.reader(pred_csv)\n",
        "    next(reader)  # Skip header\n",
        "    for row in reader:\n",
        "        # Tokenize the prediction sentence\n",
        "        predictions.append(word_tokenize(row[0]))  # Assuming the prediction text is in the first column\n",
        "\n",
        "# Ensure references and predictions have the same length\n",
        "assert len(references) == len(predictions), \"References and predictions must have the same length\"\n",
        "\n",
        "# Calculate the METEOR score for each pair of reference and prediction\n",
        "total_meteor_score = 0.0\n",
        "num_sentences = len(references)\n",
        "\n",
        "for ref, pred in zip(references, predictions):\n",
        "    score = meteor_score([ref], pred)\n",
        "    total_meteor_score += score\n",
        "\n",
        "# Calculate the average METEOR score\n",
        "avg_meteor_score = total_meteor_score / num_sentences\n",
        "\n",
        "print(f\"Khasi METEOR Score: {avg_meteor_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Tx9W_nq94q0",
        "outputId": "8786b727-03af-4cc4-ad2e-d93df9c39b78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Khasi METEOR Score: 0.3308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyter\n",
        "reference_kha_file = '/content/drive/MyDrive//multilingual/eng_to_indic/kha/actual_khasi.csv'\n",
        "hypothesis_kha_file = '/content/drive/MyDrive//multilingual/eng_to_indic/kha/prediction_khasi.csv'\n",
        "ter_score = pyter.ter(reference_kha_file, hypothesis_kha_file)\n",
        "print(f\"TER Khasi Score: {ter_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-HAoBSd94he",
        "outputId": "97cdb84d-7653-4791-d0e6-335581abc90d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TER Khasi Score: 0.10810810810810811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Manipuri**"
      ],
      "metadata": {
        "id": "kmv8U_Kf-Lbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu, SmoothingFunction\n",
        "\n",
        "# Load actual translations from actual.csv\n",
        "with open('/content/drive/MyDrive/multilingual/eng_to_indic/mni/actual.csv', 'r') as file:\n",
        "    actual_reader = csv.reader(file)\n",
        "    actual_translations = [row[0].split() for row in actual_reader]\n",
        "\n",
        "# Load predicted translations from predicted.csv\n",
        "with open('/content/drive/MyDrive//multilingual/eng_to_indic/mni/prediction.csv', 'r') as file:\n",
        "    predicted_reader = csv.reader(file)\n",
        "    predicted_translations = [row[0].split() for row in predicted_reader]\n",
        "\n",
        "# Define a smoothing function for BLEU score calculation\n",
        "smoothie = SmoothingFunction().method1\n",
        "\n",
        "# Compute BLEU score for corpus level with smoothing\n",
        "corpus_score = corpus_bleu(actual_translations, predicted_translations, smoothing_function=smoothie)\n",
        "\n",
        "# Compute BLEU score for sentence level with smoothing\n",
        "sentence_scores = [sentence_bleu([actual], predicted, smoothing_function=smoothie) for actual, predicted in zip(actual_translations, predicted_translations)]\n",
        "\n",
        "# Calculate average sentence level BLEU score\n",
        "avg_sentence_score = sum(sentence_scores) / len(sentence_scores)\n",
        "\n",
        "# Print the scores\n",
        "# print(\"Corpus BLEU score:\", corpus_score)\n",
        "print(\"Manipuri BLEU score:\", avg_sentence_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xF44rq63-QdQ",
        "outputId": "1d794c3b-e77c-439f-995c-fc4df7d63bda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manipuri BLEU score: 0.11534257897289453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import sacrebleu\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "# Load reference and prediction CSV files\n",
        "reference_file = '/content/drive/MyDrive//multilingual/eng_to_indic/mni/actual.csv'\n",
        "prediction_file = '/content/drive/MyDrive//multilingual/eng_to_indic/mni/prediction.csv'\n",
        "\n",
        "reference_df = pd.read_csv(reference_file)\n",
        "prediction_df = pd.read_csv(prediction_file)\n",
        "\n",
        "\n",
        "references = reference_df['MANIPURI'].tolist()\n",
        "predictions = prediction_df['MANIPURI'].tolist()\n",
        "\n",
        "# Calculate SacreBLEU score\n",
        "sacrebleu_score = sacrebleu.corpus_bleu(predictions, [references]).score\n",
        "print(f\" Manipuri SacreBLEU Score: {sacrebleu_score/100}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EF8FP1m-QVj",
        "outputId": "89e3ef8f-e041-46fb-bd4a-0e6c7197033a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Manipuri SacreBLEU Score: 0.13559250020888106\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "# Initialize a ROUGE scorer\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "# Load reference and prediction CSV files\n",
        "reference_file = '/content/drive/MyDrive//multilingual/eng_to_indic/mni/actual.csv'\n",
        "prediction_file = '/content/drive/MyDrive//multilingual/eng_to_indic/mni/prediction.csv'\n",
        "# Initialize lists to hold ROUGE scores\n",
        "rouge1_scores = []\n",
        "rouge2_scores = []\n",
        "rougeL_scores = []\n",
        "\n",
        "# Read reference translations from CSV file\n",
        "with open(reference_file, 'r') as ref_csv:\n",
        "    reader = csv.reader(ref_csv)\n",
        "    next(reader)  # Skip header\n",
        "    references = [row[0] for row in reader]\n",
        "\n",
        "with open(prediction_file, 'r') as pred_csv:\n",
        "    reader = csv.reader(pred_csv)\n",
        "    next(reader)  # Skip header\n",
        "    predictions = [row[0] for row in reader]\n",
        "\n",
        "# Calculate the ROUGE scores for each pair of reference and prediction\n",
        "for ref, pred in zip(references, predictions):\n",
        "    scores = scorer.score(ref, pred)\n",
        "    rouge1_scores.append(scores['rouge1'].fmeasure)\n",
        "    rouge2_scores.append(scores['rouge2'].fmeasure)\n",
        "    rougeL_scores.append(scores['rougeL'].fmeasure)\n",
        "\n",
        "# Calculate average ROUGE scores\n",
        "avg_rouge1 = sum(rouge1_scores) *10/ len(rouge1_scores)\n",
        "avg_rouge2 = sum(rouge2_scores) *10/ len(rouge2_scores)\n",
        "avg_rougeL = sum(rougeL_scores) *10 / len(rougeL_scores)\n",
        "\n",
        "# print(f\" ROUGE-1 Score: {avg_rouge1:.4f}\")\n",
        "print(f\" Manipuri ROUGE Score: {avg_rouge2:.4f}\")\n",
        "# print(f\" ROUGE-L Score: {avg_rougeL:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9be8ULK2-QOs",
        "outputId": "f77318cc-7629-46d7-e965-584984f03515"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Manipuri ROUGE Score: 0.2439\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import nltk\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "\n",
        "## Load reference and prediction CSV files\n",
        "reference_file = '/content/drive/MyDrive//multilingual/eng_to_indic/mni/actual.csv'\n",
        "prediction_file = '/content/drive/MyDrive//multilingual/eng_to_indic/mni/prediction.csv'\n",
        "# Initialize lists to hold reference and predicted sentences\n",
        "references = []\n",
        "predictions = []\n",
        "\n",
        "# Read reference translations from CSV file\n",
        "with open(reference_file, 'r') as ref_csv:\n",
        "    reader = csv.reader(ref_csv)\n",
        "    next(reader)  # Skip header\n",
        "    for row in reader:\n",
        "        # Tokenize the reference sentence\n",
        "        references.append(word_tokenize(row[0]))  # Assuming the reference text is in the first column\n",
        "\n",
        "# Read model predictions from CSV file\n",
        "with open(prediction_file, 'r') as pred_csv:\n",
        "    reader = csv.reader(pred_csv)\n",
        "    next(reader)  # Skip header\n",
        "    for row in reader:\n",
        "        # Tokenize the prediction sentence\n",
        "        predictions.append(word_tokenize(row[0]))  # Assuming the prediction text is in the first column\n",
        "\n",
        "# Ensure references and predictions have the same length\n",
        "assert len(references) == len(predictions), \"References and predictions must have the same length\"\n",
        "\n",
        "# Calculate the METEOR score for each pair of reference and prediction\n",
        "total_meteor_score = 0.0\n",
        "num_sentences = len(references)\n",
        "\n",
        "for ref, pred in zip(references, predictions):\n",
        "    score = meteor_score([ref], pred)\n",
        "    total_meteor_score += score\n",
        "\n",
        "# Calculate the average METEOR score\n",
        "avg_meteor_score = total_meteor_score / num_sentences\n",
        "\n",
        "print(f\"Manipuri METEOR Score: {avg_meteor_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4At4Kfe-QHg",
        "outputId": "47d19435-afdc-48ff-9e72-106c7e6a0704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manipuri METEOR Score: 0.2454\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyter\n",
        "reference_mni_file = '/content/drive/MyDrive//multilingual/eng_to_indic/mni/actual.csv'\n",
        "hypothesis_mni_file = '/content/drive/MyDrive//multilingual/eng_to_indic/mni/prediction.csv'\n",
        "ter_score = pyter.ter(reference_mni_file, hypothesis_mni_file)\n",
        "print(f\"TER Manipuri Score: {ter_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zb1bwoE-P_E",
        "outputId": "88bd98a7-ad48-4344-960f-a059d0d059ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TER Manipuri Score: 0.11764705882352941\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Mizo**"
      ],
      "metadata": {
        "id": "1ssCen9E-RBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu, SmoothingFunction\n",
        "\n",
        "# Load actual translations from actual.csv\n",
        "with open('/content/drive/MyDrive/multilingual/eng_to_indic/lus/actual_mizo.csv', 'r') as file:\n",
        "    actual_reader = csv.reader(file)\n",
        "    actual_translations = [row[0].split() for row in actual_reader]\n",
        "\n",
        "# Load predicted translations from predicted.csv\n",
        "with open('/content/drive/MyDrive//multilingual/eng_to_indic/lus/prediction_mizo.csv', 'r') as file:\n",
        "    predicted_reader = csv.reader(file)\n",
        "    predicted_translations = [row[0].split() for row in predicted_reader]\n",
        "\n",
        "# Define a smoothing function for BLEU score calculation\n",
        "smoothie = SmoothingFunction().method1\n",
        "\n",
        "# Compute BLEU score for corpus level with smoothing\n",
        "corpus_score = corpus_bleu(actual_translations, predicted_translations, smoothing_function=smoothie)\n",
        "\n",
        "# Compute BLEU score for sentence level with smoothing\n",
        "sentence_scores = [sentence_bleu([actual], predicted, smoothing_function=smoothie) for actual, predicted in zip(actual_translations, predicted_translations)]\n",
        "\n",
        "# Calculate average sentence level BLEU score\n",
        "avg_sentence_score = sum(sentence_scores) / len(sentence_scores)\n",
        "\n",
        "# Print the scores\n",
        "# print(\"Corpus BLEU score:\", corpus_score)\n",
        "print(\"Mizo BLEU score:\", avg_sentence_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrRVlVNr-wOW",
        "outputId": "b1ae9046-c1c4-4c61-be9b-6a39b66569f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mizo BLEU score: 0.1236120938142832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import sacrebleu\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "# Load reference and prediction CSV files\n",
        "reference_file = '/content/drive/MyDrive//multilingual/eng_to_indic/lus/actual_mizo.csv'\n",
        "prediction_file = '/content/drive/MyDrive//multilingual/eng_to_indic/lus/prediction_mizo.csv'\n",
        "\n",
        "reference_df = pd.read_csv(reference_file)\n",
        "prediction_df = pd.read_csv(prediction_file)\n",
        "\n",
        "\n",
        "references = reference_df['MIZO'].tolist()\n",
        "predictions = prediction_df['MIZO'].tolist()\n",
        "\n",
        "# Calculate SacreBLEU score\n",
        "sacrebleu_score = sacrebleu.corpus_bleu(predictions, [references]).score\n",
        "print(f\"Mizo SacreBLEU Score: {sacrebleu_score}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCSPzTpG_AVu",
        "outputId": "39083871-22a7-47e3-99b1-2b6631867611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mizo SacreBLEU Score: 14.511023703400175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load actual and prediction data from CSV files\n",
        "reference_file = '/content/drive/MyDrive//multilingual/eng_to_indic/lus/actual_mizo.csv'\n",
        "prediction_file = '/content/drive/MyDrive//multilingual/eng_to_indic/lus/prediction_mizo.csv'\n",
        "\n",
        "# Initialize lists to hold reference and predicted sentences\n",
        "references = []\n",
        "predictions = []\n",
        "\n",
        "# Read reference translations from CSV file\n",
        "with open(reference_file, 'r') as ref_csv:\n",
        "    reader = csv.reader(ref_csv)\n",
        "    next(reader)  # Skip header\n",
        "    for row in reader:\n",
        "        # Tokenize the reference sentence\n",
        "        references.append(word_tokenize(row[0]))  # Assuming the reference text is in the first column\n",
        "\n",
        "# Read model predictions from CSV file\n",
        "with open(prediction_file, 'r') as pred_csv:\n",
        "    reader = csv.reader(pred_csv)\n",
        "    next(reader)  # Skip header\n",
        "    for row in reader:\n",
        "        # Tokenize the prediction sentence\n",
        "        predictions.append(word_tokenize(row[0]))  # Assuming the prediction text is in the first column\n",
        "\n",
        "# Ensure references and predictions have the same length\n",
        "assert len(references) == len(predictions), \"References and predictions must have the same length\"\n",
        "\n",
        "# Calculate the METEOR score for each pair of reference and prediction\n",
        "total_meteor_score = 0.0\n",
        "num_sentences = len(references)\n",
        "\n",
        "for ref, pred in zip(references, predictions):\n",
        "    score = meteor_score([ref], pred)\n",
        "    total_meteor_score += score\n",
        "\n",
        "# Calculate the average METEOR score\n",
        "avg_meteor_score = total_meteor_score / num_sentences\n",
        "\n",
        "print(f\"Mizo METEOR Score: {avg_meteor_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_Zo1ZGB_DL5",
        "outputId": "155a797c-3be0-4e9d-950d-aea1592344d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mizo METEOR Score: 0.2743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "# Initialize a ROUGE scorer\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "\n",
        "# Load actual and prediction data from CSV files\n",
        "reference_file = '/content/drive/MyDrive//multilingual/eng_to_indic/lus/actual_mizo.csv'\n",
        "prediction_file = '/content/drive/MyDrive//multilingual/eng_to_indic/lus/prediction_mizo.csv'\n",
        "\n",
        "# Initialize lists to hold ROUGE scores\n",
        "rouge1_scores = []\n",
        "rouge2_scores = []\n",
        "rougeL_scores = []\n",
        "\n",
        "# Read reference translations from CSV file\n",
        "with open(reference_file, 'r') as ref_csv:\n",
        "    reader = csv.reader(ref_csv)\n",
        "    next(reader)  # Skip header\n",
        "    references = [row[0] for row in reader]\n",
        "\n",
        "with open(prediction_file, 'r') as pred_csv:\n",
        "    reader = csv.reader(pred_csv)\n",
        "    next(reader)  # Skip header\n",
        "    predictions = [row[0] for row in reader]\n",
        "\n",
        "# Calculate the ROUGE scores for each pair of reference and prediction\n",
        "for ref, pred in zip(references, predictions):\n",
        "    scores = scorer.score(ref, pred)\n",
        "    rouge1_scores.append(scores['rouge1'].fmeasure)\n",
        "    rouge2_scores.append(scores['rouge2'].fmeasure)\n",
        "    rougeL_scores.append(scores['rougeL'].fmeasure)\n",
        "\n",
        "# Calculate average ROUGE scores\n",
        "avg_rouge1 = sum(rouge1_scores) / len(rouge1_scores)\n",
        "avg_rouge2 = sum(rouge2_scores) / len(rouge2_scores)\n",
        "avg_rougeL = sum(rougeL_scores) / len(rougeL_scores)\n",
        "\n",
        "#print(f\"ROUGE-1 Score: {avg_rouge1:.4f}\")\n",
        "print(f\"Mizo ROUGE Score: {avg_rouge2:.4f}\")\n",
        "# print(f\"ROUGE-L Score: {avg_rougeL:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGNK7sFc_OGD",
        "outputId": "a5a63453-eb79-4619-d05d-43eefad209a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mizo ROUGE Score: 0.1618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyter\n",
        "reference_lus_file = '/content/drive/MyDrive//multilingual/eng_to_indic/lus/actual_mizo.csv'\n",
        "hypothesis_lus_file = '/content/drive/MyDrive//multilingual/eng_to_indic/lus/prediction_mizo.csv'\n",
        "ter_score = pyter.ter(reference_lus_file, hypothesis_lus_file)\n",
        "print(f\"TER Mizo Score: {ter_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_OGH3jj_QAq",
        "outputId": "792ac2d8-9274-4ade-91fc-332910ba0c05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TER Mizo Score: 0.1095890410958904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Nepali**"
      ],
      "metadata": {
        "id": "EkNjWBwj_Skj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu, SmoothingFunction\n",
        "\n",
        "# Load actual translations from actual.csv\n",
        "with open('/content/drive/MyDrive//multilingual/eng_to_indic/npi/actual.csv', 'r') as file:\n",
        "    actual_reader = csv.reader(file)\n",
        "    actual_translations = [row[0].split() for row in actual_reader]\n",
        "\n",
        "# Load predicted translations from predicted.csv\n",
        "with open('/content/drive/MyDrive//multilingual/eng_to_indic/npi/prediction_nepali.csv', 'r') as file:\n",
        "    predicted_reader = csv.reader(file)\n",
        "    predicted_translations = [row[0].split() for row in predicted_reader]\n",
        "\n",
        "# Define a smoothing function for BLEU score calculation\n",
        "smoothie = SmoothingFunction().method1\n",
        "\n",
        "# Compute BLEU score for corpus level with smoothing\n",
        "corpus_score = corpus_bleu(actual_translations, predicted_translations, smoothing_function=smoothie)\n",
        "\n",
        "# Compute BLEU score for sentence level with smoothing\n",
        "sentence_scores = [sentence_bleu([actual], predicted, smoothing_function=smoothie) for actual, predicted in zip(actual_translations, predicted_translations)]\n",
        "\n",
        "# Calculate average sentence level BLEU score\n",
        "avg_sentence_score = sum(sentence_scores) / len(sentence_scores)\n",
        "\n",
        "# Print the scores\n",
        "# print(\"Corpus BLEU score:\", corpus_score)\n",
        "print(\"Nepali BLEU score:\", avg_sentence_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QE7QntvP_YjE",
        "outputId": "9ef92096-6afb-4d45-b556-2d531bdd0df8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nepali BLEU score: 0.3100018077218886\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import sacrebleu\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "# Load reference and prediction CSV files\n",
        "reference_file = '/content/drive/MyDrive//multilingual/eng_to_indic/npi/actual.csv'\n",
        "prediction_file = '/content/drive/MyDrive//multilingual/eng_to_indic/npi/prediction_nepali.csv'\n",
        "\n",
        "reference_df = pd.read_csv(reference_file)\n",
        "prediction_df = pd.read_csv(prediction_file)\n",
        "\n",
        "\n",
        "\n",
        "references = reference_df['NEPALI'].tolist()\n",
        "predictions = prediction_df['NEPALI'].tolist()\n",
        "\n",
        "# Calculate SacreBLEU score\n",
        "sacrebleu_score = sacrebleu.corpus_bleu(predictions, [references]).score\n",
        "print(f\"SacreBLEU Score: {sacrebleu_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq5Ol2BC_ZWr",
        "outputId": "7c21616c-3c37-4773-ccd2-60f05dd0d411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SacreBLEU Score: 30.70280451518892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import nltk\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "# File paths\n",
        "reference_file = '/content/drive/MyDrive//multilingual/eng_to_indic/npi/actual.csv'  # Path to the CSV file containing reference Nepali translations\n",
        "prediction_file = '/content/drive/MyDrive//multilingual/eng_to_indic/npi/prediction_nepali.csv'  # Path to the CSV file containing model's predicted Nepali translations\n",
        "\n",
        "# Initialize lists to hold reference and predicted sentences\n",
        "references = []\n",
        "predictions = []\n",
        "\n",
        "# Read reference translations from CSV file\n",
        "with open(reference_file, 'r') as ref_csv:\n",
        "    reader = csv.reader(ref_csv)\n",
        "    next(reader)  # Skip header\n",
        "    for row in reader:\n",
        "        # Tokenize the reference sentence\n",
        "        references.append(word_tokenize(row[0]))  # Assuming the reference text is in the first column\n",
        "\n",
        "# Read model predictions from CSV file\n",
        "with open(prediction_file, 'r') as pred_csv:\n",
        "    reader = csv.reader(pred_csv)\n",
        "    next(reader)  # Skip header\n",
        "    for row in reader:\n",
        "        # Tokenize the prediction sentence\n",
        "        predictions.append(word_tokenize(row[0]))  # Assuming the prediction text is in the first column\n",
        "\n",
        "# Ensure references and predictions have the same length\n",
        "assert len(references) == len(predictions), \"References and predictions must have the same length\"\n",
        "\n",
        "# Calculate the METEOR score for each pair of reference and prediction\n",
        "total_meteor_score = 0.0\n",
        "num_sentences = len(references)\n",
        "\n",
        "for ref, pred in zip(references, predictions):\n",
        "    score = meteor_score([ref], pred)\n",
        "    total_meteor_score += score\n",
        "\n",
        "# Calculate the average METEOR score\n",
        "avg_meteor_score = total_meteor_score / num_sentences\n",
        "\n",
        "print(f\"Nepali METEOR Score: {avg_meteor_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HYw5RH6_ZOt",
        "outputId": "d4549281-edc5-4508-aa9d-918ab6d9b7b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nepali METEOR Score: 0.3593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "# Initialize a ROUGE scorer\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "# File paths\n",
        "reference_file = '/content/drive/MyDrive//multilingual/eng_to_indic/npi/actual.csv'  # Path to the CSV file containing reference Nepali translations\n",
        "prediction_file = '/content/drive/MyDrive//multilingual/eng_to_indic/npi/prediction_nepali.csv'  # Path to the CSV file containing model's predicted Nepali translations\n",
        "\n",
        "# Initialize lists to hold ROUGE scores\n",
        "rouge1_scores = []\n",
        "rouge2_scores = []\n",
        "rougeL_scores = []\n",
        "\n",
        "# Read reference translations from CSV file\n",
        "with open(reference_file, 'r') as ref_csv:\n",
        "    reader = csv.reader(ref_csv)\n",
        "    next(reader)  # Skip header\n",
        "    references = [row[0] for row in reader]\n",
        "\n",
        "with open(prediction_file, 'r') as pred_csv:\n",
        "    reader = csv.reader(pred_csv)\n",
        "    next(reader)  # Skip header\n",
        "    predictions = [row[0] for row in reader]\n",
        "\n",
        "# Calculate the ROUGE scores for each pair of reference and prediction\n",
        "for ref, pred in zip(references, predictions):\n",
        "    scores = scorer.score(ref, pred)\n",
        "    rouge1_scores.append(scores['rouge1'].fmeasure)\n",
        "    rouge2_scores.append(scores['rouge2'].fmeasure)\n",
        "    rougeL_scores.append(scores['rougeL'].fmeasure)\n",
        "\n",
        "# Calculate average ROUGE scores\n",
        "avg_rouge1 = sum(rouge1_scores) *10/ len(rouge1_scores)\n",
        "avg_rouge2 = sum(rouge2_scores) *10/ len(rouge2_scores)\n",
        "avg_rougeL = sum(rougeL_scores) *10 / len(rougeL_scores)\n",
        "\n",
        "\n",
        "# print(f\"ROUGE-1 Score: {avg_rouge1:.4f}\")\n",
        "print(f\"Nepali ROUGE Score: {avg_rouge2:.4f}\")\n",
        "# print(f\"ROUGE-L Score: {avg_rougeL:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_IftnhF_ZHN",
        "outputId": "e655406b-7d78-4aac-da4e-115e3c773985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nepali ROUGE Score: 0.1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyter\n",
        "reference_npi_file = '/content/drive/MyDrive//multilingual/eng_to_indic/npi/actual.csv'\n",
        "hypothesis_npi_file = '/content/drive/MyDrive//multilingual/eng_to_indic/npi/prediction_nepali.csv'\n",
        "ter_score = pyter.ter(reference_npi_file, hypothesis_npi_file)\n",
        "print(f\"TER Nepali Score: {ter_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thJdNQY-_Y-n",
        "outputId": "f1a18e03-2cd2-4eca-f407-ee03efc78e95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TER Nepali Score: 0.17333333333333334\n"
          ]
        }
      ]
    }
  ]
}
